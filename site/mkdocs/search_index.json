{
    "docs": [
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Home"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/gs_introduction/", 
            "text": "Introduction\n\n\nSoftware engineering is the study of ways in which to create large and complex computer applications and that generally involve many programmers and designers. At the heart of software engineering is with the overall design of the applications and on the creation of a design that is based on the needs and requirements of end users. While software engineering involves the full life cycle of a software project, is includes many different components - specification, requirements gathering, design, verification, coding, testing, quality assurance, user acceptance testing, production, and ongoing maintenance.\n\n\nHaving an in-depth understanding on every component of software engineering is not mandatory, however, it is important to understand that the subject of data structures and algorithms is concerned with the coding phase. The use of data structures and algorithms is the nuts-and-blots used by programmers to store and manipulate data.\n\n\nThis article, along with the other examples in this section focuses on the essentials of data structures and algorithms. Attempts will be made to understand how they work, which structure or algorithm is best in a particular situation in an easy to understand environment.\n\n\nData Structures and Algorithms - Defined\n\n\nA data structure is an arrangement of data in a computer's memory or even disk storage. An example of several common data structures are arrays, linked lists, queues, stacks, binary trees, and hash tables. Algorithms, on the other hand, are used to manipulate the data contained in these data structures as in searching and sorting.\n\n\nMany algorithms apply directly to a specific data structures. When working with certain data structures you need to know how to insert new data, search for a specified item, and deleting a specific item.\n\n\nCommonly used algorithms include are useful for:\n\n\n\n\nSearching for a particular data item (or record).\n\n\nSorting the data. There are many ways to sort data. Simple sorting, Advanced sorting\n\n\nIterating through all the items in a data structure. (Visiting each item in turn so as to display it or perform some other action on these items)", 
            "title": "Introduction"
        }, 
        {
            "location": "/gs_introduction/#introduction", 
            "text": "Software engineering is the study of ways in which to create large and complex computer applications and that generally involve many programmers and designers. At the heart of software engineering is with the overall design of the applications and on the creation of a design that is based on the needs and requirements of end users. While software engineering involves the full life cycle of a software project, is includes many different components - specification, requirements gathering, design, verification, coding, testing, quality assurance, user acceptance testing, production, and ongoing maintenance.  Having an in-depth understanding on every component of software engineering is not mandatory, however, it is important to understand that the subject of data structures and algorithms is concerned with the coding phase. The use of data structures and algorithms is the nuts-and-blots used by programmers to store and manipulate data.  This article, along with the other examples in this section focuses on the essentials of data structures and algorithms. Attempts will be made to understand how they work, which structure or algorithm is best in a particular situation in an easy to understand environment.", 
            "title": "Introduction"
        }, 
        {
            "location": "/gs_introduction/#data-structures-and-algorithms-defined", 
            "text": "A data structure is an arrangement of data in a computer's memory or even disk storage. An example of several common data structures are arrays, linked lists, queues, stacks, binary trees, and hash tables. Algorithms, on the other hand, are used to manipulate the data contained in these data structures as in searching and sorting.  Many algorithms apply directly to a specific data structures. When working with certain data structures you need to know how to insert new data, search for a specified item, and deleting a specific item.  Commonly used algorithms include are useful for:   Searching for a particular data item (or record).  Sorting the data. There are many ways to sort data. Simple sorting, Advanced sorting  Iterating through all the items in a data structure. (Visiting each item in turn so as to display it or perform some other action on these items)", 
            "title": "Data Structures and Algorithms - Defined"
        }, 
        {
            "location": "/gs_greedy_algorithms/", 
            "text": "Greedy Algorithms\n\n\nAn algorithm is designed to achieve optimum solution for a given problem. In greedy algorithm approach, decisions are made from the given solution domain. As being greedy, the closest solution that seems to provide an optimum solution is chosen.\n\n\nGreedy algorithms try to find a localized optimum solution, which may eventually lead to globally optimized solutions. However, generally greedy algorithms do not provide globally optimized solutions.\n\n\nCounting Coins\n\n\nThis problem is to count to a desired value by choosing the least possible coins and the greedy approach forces the algorithm to pick the largest possible coin. If we are provided coins of 1, 2, 5 and 10 and we are asked to count 18 then the greedy procedure will be\n\n\n\n\n\n\nSelect one 10 coin, the remaining count is 8\n\n\n\n\n\n\nThen select one 5 coin, the remaining count is 3\n\n\n\n\n\n\nThen select one 2 coin, the remaining count is 1\n\n\n\n\n\n\nAnd finally, the selection of one 1 coins solves the problem\n\n\n\n\n\n\nThough, it seems to be working fine, for this count we need to pick only 4 coins. But if we slightly change the problem then the same approach may not be able to produce the same optimum result.\n\n\nFor the currency system, where we have coins of 1, 7, 10 value, counting coins for value 18 will be absolutely optimum but for count like 15, it may use more coins than necessary. For example, the greedy approach will use 10 + 1 + 1 + 1 + 1 + 1, total 6 coins. Whereas the same problem could be solved by using only 3 coins (7 + 7 + 1)\n\n\nHence, we may conclude that the greedy approach picks an immediate optimized solution and may fail where global optimization is a major concern.\n\n\nExamples\n\n\nMost networking algorithms use the greedy approach. Here is a list of few of them\n\n\n\n\nTravelling Salesman Problem\n\n\nPrim's Minimal Spanning Tree Algorithm\n\n\nKruskal's Minimal Spanning Tree Algorithm\n\n\nDijkstra's Minimal Spanning Tree Algorithm\n\n\nGraph - Map Coloring\n\n\nGraph - Vertex Cover\n\n\nKnapsack Problem\n\n\nJob Scheduling Problem\n\n\n\n\nThere are lots of similar problems that uses the greedy approach to find an optimum solution.", 
            "title": "Greedy Algorithms"
        }, 
        {
            "location": "/gs_greedy_algorithms/#greedy-algorithms", 
            "text": "An algorithm is designed to achieve optimum solution for a given problem. In greedy algorithm approach, decisions are made from the given solution domain. As being greedy, the closest solution that seems to provide an optimum solution is chosen.  Greedy algorithms try to find a localized optimum solution, which may eventually lead to globally optimized solutions. However, generally greedy algorithms do not provide globally optimized solutions.", 
            "title": "Greedy Algorithms"
        }, 
        {
            "location": "/gs_greedy_algorithms/#counting-coins", 
            "text": "This problem is to count to a desired value by choosing the least possible coins and the greedy approach forces the algorithm to pick the largest possible coin. If we are provided coins of 1, 2, 5 and 10 and we are asked to count 18 then the greedy procedure will be    Select one 10 coin, the remaining count is 8    Then select one 5 coin, the remaining count is 3    Then select one 2 coin, the remaining count is 1    And finally, the selection of one 1 coins solves the problem    Though, it seems to be working fine, for this count we need to pick only 4 coins. But if we slightly change the problem then the same approach may not be able to produce the same optimum result.  For the currency system, where we have coins of 1, 7, 10 value, counting coins for value 18 will be absolutely optimum but for count like 15, it may use more coins than necessary. For example, the greedy approach will use 10 + 1 + 1 + 1 + 1 + 1, total 6 coins. Whereas the same problem could be solved by using only 3 coins (7 + 7 + 1)  Hence, we may conclude that the greedy approach picks an immediate optimized solution and may fail where global optimization is a major concern.", 
            "title": "Counting Coins"
        }, 
        {
            "location": "/gs_greedy_algorithms/#examples", 
            "text": "Most networking algorithms use the greedy approach. Here is a list of few of them   Travelling Salesman Problem  Prim's Minimal Spanning Tree Algorithm  Kruskal's Minimal Spanning Tree Algorithm  Dijkstra's Minimal Spanning Tree Algorithm  Graph - Map Coloring  Graph - Vertex Cover  Knapsack Problem  Job Scheduling Problem   There are lots of similar problems that uses the greedy approach to find an optimum solution.", 
            "title": "Examples"
        }, 
        {
            "location": "/gs_divide_and_conquer/", 
            "text": "Divide and Conquer\n\n\nIn divide and conquer approach, the problem in hand, is divided into smaller sub-problems and then each problem is solved independently. When we keep on dividing the subproblems into even smaller sub-problems, we may eventually reach a stage where no more division is possible. Those \"atomic\" smallest possible sub-problem (fractions) are solved. The solution of all sub-problems is finally merged in order to obtain the solution of an original problem.\n\n\n\n\nBroadly, we can understand \ndivide-and-conquer\n approach in a three-step process.\n\n\nDivide/Break\n\n\nThis step involves breaking the problem into smaller sub-problems. Sub-problems should represent a part of the original problem. This step generally takes a recursive approach to divide the problem until no sub-problem is further divisible. At this stage, sub-problems become atomic in nature but still represent some part of the actual problem.\n\n\nConquer/Solve\n\n\nThis step receives a lot of smaller sub-problems to be solved. Generally, at this level, the problems are considered 'solved' on their own.\n\n\nMerge/Combine\n\n\nWhen the smaller sub-problems are solved, this stage recursively combines them until they formulate a solution of the original problem. This algorithmic approach works recursively and conquer \n merge steps works so close that they appear as one.\n\n\nExamples\n\n\nThe following computer algorithms are based on divide-and-conquer programming approach\n\n\n\n\nMerge Sort\n\n\nQuick Sort\n\n\nBinary Search\n\n\nStrassen's Matrix Multiplication\n\n\nClosest pair (points)\n\n\n\n\nThere are various ways available to solve any computer problem, but the mentioned are a good example of divide and conquer approach.", 
            "title": "Divide-and-Conquer"
        }, 
        {
            "location": "/gs_divide_and_conquer/#divide-and-conquer", 
            "text": "In divide and conquer approach, the problem in hand, is divided into smaller sub-problems and then each problem is solved independently. When we keep on dividing the subproblems into even smaller sub-problems, we may eventually reach a stage where no more division is possible. Those \"atomic\" smallest possible sub-problem (fractions) are solved. The solution of all sub-problems is finally merged in order to obtain the solution of an original problem.   Broadly, we can understand  divide-and-conquer  approach in a three-step process.", 
            "title": "Divide and Conquer"
        }, 
        {
            "location": "/gs_divide_and_conquer/#dividebreak", 
            "text": "This step involves breaking the problem into smaller sub-problems. Sub-problems should represent a part of the original problem. This step generally takes a recursive approach to divide the problem until no sub-problem is further divisible. At this stage, sub-problems become atomic in nature but still represent some part of the actual problem.", 
            "title": "Divide/Break"
        }, 
        {
            "location": "/gs_divide_and_conquer/#conquersolve", 
            "text": "This step receives a lot of smaller sub-problems to be solved. Generally, at this level, the problems are considered 'solved' on their own.", 
            "title": "Conquer/Solve"
        }, 
        {
            "location": "/gs_divide_and_conquer/#mergecombine", 
            "text": "When the smaller sub-problems are solved, this stage recursively combines them until they formulate a solution of the original problem. This algorithmic approach works recursively and conquer   merge steps works so close that they appear as one.", 
            "title": "Merge/Combine"
        }, 
        {
            "location": "/gs_divide_and_conquer/#examples", 
            "text": "The following computer algorithms are based on divide-and-conquer programming approach   Merge Sort  Quick Sort  Binary Search  Strassen's Matrix Multiplication  Closest pair (points)   There are various ways available to solve any computer problem, but the mentioned are a good example of divide and conquer approach.", 
            "title": "Examples"
        }, 
        {
            "location": "/gs_dynamic_programming/", 
            "text": "Dynamic Programming\n\n\nDynamic programming approach is similar to divide and conquer in breaking down the problem into smaller and yet smaller possible sub-problems. But unlike, divide and conquer, these sub-problems are not solved independently. Rather, results of these smaller sub-problems are remembered and used for similar or overlapping sub-problems.\n\n\nDynamic programming is used where we have problems, which can be divided into similar sub-problems, so that their results can be re-used. Mostly, these algorithms are used for optimization. Before solving the in-hand sub-problem, dynamic algorithm will try to examine the results of the previously solved sub-problems. The solutions of sub-problems are combined in order to achieve the best solution.\n\n\nSo we can say that\n\n\n\n\nThe problem should be able to be divided into smaller overlapping sub-problem.\n\n\nAn optimum solution can be achieved by using an optimum solution of smaller sub-problems.\n\n\nDynamic algorithms use memorization.\n\n\n\n\nComparison\n\n\nIn contrast to greedy algorithms, where local optimization is addressed, dynamic algorithms are motivated for an overall optimization of the problem.\n\n\nIn contrast to divide and conquer algorithms, where solutions are combined to achieve an overall solution, dynamic algorithms use the output of a smaller sub-problem and then try to optimize a bigger sub-problem. Dynamic algorithms use memorization to remember the output of already solved sub-problems.\n\n\nExample\n\n\nThe following computer problems can be solved using dynamic programming approach\n\n\n\n\nFibonacci number series\n\n\nKnapsack problem\n\n\nTower of Hanoi\n\n\nAll pair shortest path by Floyd-Warshall\n\n\nShortest path by Dijkstra\n\n\nProject scheduling\n\n\n\n\nDynamic programming can be used in both top-down and bottom-up manner. And of course, most of the times, referring to the previous solution output is cheaper than recomputing in terms of CPU cycles.", 
            "title": "Dynamic Programming"
        }, 
        {
            "location": "/gs_dynamic_programming/#dynamic-programming", 
            "text": "Dynamic programming approach is similar to divide and conquer in breaking down the problem into smaller and yet smaller possible sub-problems. But unlike, divide and conquer, these sub-problems are not solved independently. Rather, results of these smaller sub-problems are remembered and used for similar or overlapping sub-problems.  Dynamic programming is used where we have problems, which can be divided into similar sub-problems, so that their results can be re-used. Mostly, these algorithms are used for optimization. Before solving the in-hand sub-problem, dynamic algorithm will try to examine the results of the previously solved sub-problems. The solutions of sub-problems are combined in order to achieve the best solution.  So we can say that   The problem should be able to be divided into smaller overlapping sub-problem.  An optimum solution can be achieved by using an optimum solution of smaller sub-problems.  Dynamic algorithms use memorization.", 
            "title": "Dynamic Programming"
        }, 
        {
            "location": "/gs_dynamic_programming/#comparison", 
            "text": "In contrast to greedy algorithms, where local optimization is addressed, dynamic algorithms are motivated for an overall optimization of the problem.  In contrast to divide and conquer algorithms, where solutions are combined to achieve an overall solution, dynamic algorithms use the output of a smaller sub-problem and then try to optimize a bigger sub-problem. Dynamic algorithms use memorization to remember the output of already solved sub-problems.", 
            "title": "Comparison"
        }, 
        {
            "location": "/gs_dynamic_programming/#example", 
            "text": "The following computer problems can be solved using dynamic programming approach   Fibonacci number series  Knapsack problem  Tower of Hanoi  All pair shortest path by Floyd-Warshall  Shortest path by Dijkstra  Project scheduling   Dynamic programming can be used in both top-down and bottom-up manner. And of course, most of the times, referring to the previous solution output is cheaper than recomputing in terms of CPU cycles.", 
            "title": "Example"
        }, 
        {
            "location": "/7_steps/", 
            "text": "7 Steps to Solve Algorithm Problems\n\n\nToday, I viewed the video \"7 Steps to Solve Algorithm Problems\" by Gayle Laakmann McDowell - the author of \nCracking the Coding Interview\n book. In this video, Gayle describe her method for solve algorithms problems which consists 7 steps: listen carefully, example, brute force, optimize, walk through your algorithms, code and test. In this article, I will summary these steps base on what I learned from this video.\n\n\nStep 1: Listen carefully\n\n\n\n\nEvery single detail in a question is necessary to solve it.\n\n\n\n\nThe first step is to listen carefully to the problem. So, generally speaking every single detail in a question is necessary to solve that problem - either to solve it all or to solve it optimally. So if there's some detail you haven't used in the question in your algorithm so far think about how you can put that to use because it might be necessary to solve the problem optimally.\n\n\nLet me give you an example.\n\n\nYou have two arrays, sorted and distinct\nHow did you find the number of elements in common between the two arrays?\n\n\n\n\nA lot of people solve this problem and they'll get kind of stuck for awhile and what they'll do is they'll be solving the problem and they'll know the arrays are sorted but they haven't actually used the fact that it's sorted.\n\n\nThis \nsorting\n detail - it's not necessary just to find an algorithm but it is necessary to solve the problem optimally.\n\n\nSo remember every single detail in the problem and make sure you use it.\n\n\nStep 2: Example\n\n\n\n\nMake example big, no special cases\n\n\n\n\nThe second piece is to come up with a good example, so the last problem that I gave two arrays \nsorted\n and \ndistinct\n compute the number of elements in common, most people's examples look like this.\n\n\n# too small and special case\nA: 1, 5, 15, 20\nB: 2, 5, 13, 30\n\n\n\n\nYes technically if it's a problem but it's not very useful.\n\n\nAs soon as you glance at this example you notice that there's only one element common and you know exactly what it is and it's obvious because this example is so small and it's actually kind of a special case.\n\n\nA better example is something like this\n\n\n# larger and avoid special cases\nA: 1, 5, 15, 20, 30, 37\nB: 2, 5, 13, 30, 32, 35, 37, 42\n\n\n\n\nIt's much larger and you've avoided some special cases. One of the easiest ways of improving your performance on algorithm questions is just make your examples \nlarger\n and really \navoid special cases\n.\n\n\nStep 3: Brute force\n\n\n\n\nBetter to have a brute force than nothing at all\n\n\n\n\nThe third step is to come up with a brute force algorithm. Now I'm not saying you need to go out of your way to come up with something slow, I'm really just saying, hey if the first thing you have is only something really really slow and terrible that's okay. It is so much better to start off with something slow then to start off with nothing at all. So it's fine if your first algorithm is slow and terrible whatever. However, and this is very very very important, I'm not saying to code the brute force. I'm saying just state your brute force algorithm, state its runtime, and then immediately go to optimizing.\n\n\nA good chunk of the time on algorithm interview question will often be spent on optimizations. So that's step 4 and spend some good time on it.\n\n\nStep 4: Optimize\n\n\nThe fourth step is optimize and spend some good time on it.\n\n\nStep 5: Walk through your algorithms\n\n\n\n\nKnow exactly what you're going to do before coding\n\n\n\n\n\n\nwhat variables \n data structures?\n\n\nhow, why, why do they change?\n\n\nwhat is the structure of your code\n\n\n\n\nThen once you have an optimal algorithm or you're ready to start coding take a step back and just make sure you \nknow exactly\n what you're going to do in your code.\n\n\nSo many people code prematurely when they aren't really really comfortable with what they're about to do and it ends in disaster. An eighty percent understanding of what you're about to write is really not enough for a whiteboard especially. So take a moment and walk through your algorithm and make sure you know exactly what you're about to do.\n\n\nStep 6: Code\n\n\n\n\nUse space wisely, coding style matters, modularize\n\n\n\n\nStep 6 is to start coding and I'm gonna go into this in a bit of detail. So a couple things to keep in mind particularly when you're coding on a whiteboard. The first couple tips are kind of whiteboard specific but try to write your lines straight. I'm not gonna be judging you on your handwriting and things like that but when people start writing their lines and sharp angles they start to lose track over whether this if statement under this for loop or not. The second thing is use your board space wisely. If you don't need stuff up on the board anymore just erase it. Try to write in this top left corner etc.\n\n\nBasically give yourself as much space as you possibly can to write your code. If you do run out of space though, it's ok to use arrows, that's fine, I'm really not gonna be judging you on this kind of stuff. So more important things.\n\n\nCoding style matters\n (\nconsistent braces\n, \nconsistent variable naming\n, \nconsistence spaces\n, \ndescriptive variables\n)\n\n\nCoding style matters even on a whiteboard but on a computer as well, so that means things like braces, naming conventions, or using camel case or underscores, things like that. Those kind of style things absolutely matter. I'm not that concerned over which style you pick, I don't care if you write braces on the same line or the next line but I do care a lot that you have a style and you stick to it. So be consistent in your style. When it comes to variable names, yeah I know it's an annoying to write long variable names on a whiteboard but descriptive variable names are important to good style. So one compromise here is write the good descriptive variable name first and then just ask your interviewer, hey is it okay if I abbreviate this the next time. So that'll be a nice little compromise - you'd show that you care about good variable names but you also don't waste a lot of time.\n\n\nModularize\n (\nbefore. not after\n)\n\n\nLast thing I want to talk about is modularization. Modularize your code up front and just any little conceptual chunks of code, push that off to another function. So suppose you have three steps in your algorithm - process the first string, process the second string,  and then compare the results. Don't start writing these for loops that walk through each string in the very beginning. Instead write this overall function that wraps these three steps. So step one, step two, step three, and then start drilling in and going into all the details there. Remember any conceptual chunks of code push those off to other functions, don't write them in line. \n\n\nStep 7: Test\n\n\n\n\nAnalyse: think about each line, double check things that look weired/risky (for-loop that decrement, math) \n\n\nUse test cases (smaller test-cases first (faster to run, you will problably be more through, edge cases, big test cases)\n\n\n\n\nThen once you're done with the coding you have to start testing your code. One of the mistakes a lot of people do here is they take their big example from step 2 and throw that in as a test case. The problem with that is it's very large so it will take you a long time to run through but also you just used that to develop your code, so if here's an oversight there, the problem will probably repeat itself here. \n\n\nWhat's a better step to do, what's a better process to do, is just walk through your code line by line and just think about each line up front not with the test case but just consider, is it really doing the right thing?\n\n\nDouble check anything that looks weird, so for loops that decrement instead of increment and any math at all is a really common place for errors. Just think, look at your code analytically and think what are the most likely places for errors to be and double-check those.\n\n\nStart with small rather than big\n\n\nThen once you start with actual test cases start with small test cases rather than big ones. Small test cases work pretty much as effectively as big test cases but they are so much faster to run through, and in fact because they're faster people tend to be much more thorough so you're much more likely to actually find bugs with small test cases than big test cases. So start with small test cases then go in to edge cases after that and then if you have time maybe throw in some big test cases. A couple last techniques with testing. The first one is make sure that when you're testing you're really thinking about what you're doing. A lot of people when they're testing they're just walking through their code almost like they're a bot, and they only look to see if things made sense at the very end when they look at their output. It's much better to really think as you're testing, this way you find the bug as soon as it happens rather than six lines later at the very bottom.\n\n\nTest your code not your algorithm\n\n\nThe second thing is when you're testing make sure that you're actually testing your code and not your algorithm. An amazing number of people will just take their example and like just walk through it again as though they're just walking through their algorithm but they're never even looking at their code, they're not looking at the exact calculations their code actually did. So make sure that you're really testing your code.\n\n\nFind bugs\n\n\nThen the last thing is when you find in a bug, don't panic. Just really think about what caused the bug. A lot of times people will panic and just try to make the first fix that fixes it for that output but they haven't really given it some thought and then they're in a much worse position because if you make the wrong fix to your code, the thing that just fixed the output but didn't fix a real bug you've not fixed the actual bug, you've made your code more complex, and you potentially introduced a brand new bug and you're in a much worse position. It's much better to just when you find the bug, it's ok, it's not that big of a deal to have a bug it's very normal just really think through what the actual bug, where the actual plug came from.\n\n\nRemember\n\n\n\n\nthink as you test (don't be a bot)\n\n\ntest your code, not your algorithm\n\n\nthink before you fix bugs. Don't panic! (wrong fixes are worse than no fix)\n\n\n\n\nSuggested Reading\n\n\n\n\n7 Steps to Solve Algorithm Problems. Gayle Laakmann McDowell", 
            "title": "7 Steps to Solve Algorithm Problems"
        }, 
        {
            "location": "/7_steps/#7-steps-to-solve-algorithm-problems", 
            "text": "Today, I viewed the video \"7 Steps to Solve Algorithm Problems\" by Gayle Laakmann McDowell - the author of  Cracking the Coding Interview  book. In this video, Gayle describe her method for solve algorithms problems which consists 7 steps: listen carefully, example, brute force, optimize, walk through your algorithms, code and test. In this article, I will summary these steps base on what I learned from this video.", 
            "title": "7 Steps to Solve Algorithm Problems"
        }, 
        {
            "location": "/7_steps/#step-1-listen-carefully", 
            "text": "Every single detail in a question is necessary to solve it.   The first step is to listen carefully to the problem. So, generally speaking every single detail in a question is necessary to solve that problem - either to solve it all or to solve it optimally. So if there's some detail you haven't used in the question in your algorithm so far think about how you can put that to use because it might be necessary to solve the problem optimally.  Let me give you an example.  You have two arrays, sorted and distinct\nHow did you find the number of elements in common between the two arrays?  A lot of people solve this problem and they'll get kind of stuck for awhile and what they'll do is they'll be solving the problem and they'll know the arrays are sorted but they haven't actually used the fact that it's sorted.  This  sorting  detail - it's not necessary just to find an algorithm but it is necessary to solve the problem optimally.  So remember every single detail in the problem and make sure you use it.", 
            "title": "Step 1: Listen carefully"
        }, 
        {
            "location": "/7_steps/#step-2-example", 
            "text": "Make example big, no special cases   The second piece is to come up with a good example, so the last problem that I gave two arrays  sorted  and  distinct  compute the number of elements in common, most people's examples look like this.  # too small and special case\nA: 1, 5, 15, 20\nB: 2, 5, 13, 30  Yes technically if it's a problem but it's not very useful.  As soon as you glance at this example you notice that there's only one element common and you know exactly what it is and it's obvious because this example is so small and it's actually kind of a special case.  A better example is something like this  # larger and avoid special cases\nA: 1, 5, 15, 20, 30, 37\nB: 2, 5, 13, 30, 32, 35, 37, 42  It's much larger and you've avoided some special cases. One of the easiest ways of improving your performance on algorithm questions is just make your examples  larger  and really  avoid special cases .", 
            "title": "Step 2: Example"
        }, 
        {
            "location": "/7_steps/#step-3-brute-force", 
            "text": "Better to have a brute force than nothing at all   The third step is to come up with a brute force algorithm. Now I'm not saying you need to go out of your way to come up with something slow, I'm really just saying, hey if the first thing you have is only something really really slow and terrible that's okay. It is so much better to start off with something slow then to start off with nothing at all. So it's fine if your first algorithm is slow and terrible whatever. However, and this is very very very important, I'm not saying to code the brute force. I'm saying just state your brute force algorithm, state its runtime, and then immediately go to optimizing.  A good chunk of the time on algorithm interview question will often be spent on optimizations. So that's step 4 and spend some good time on it.", 
            "title": "Step 3: Brute force"
        }, 
        {
            "location": "/7_steps/#step-4-optimize", 
            "text": "The fourth step is optimize and spend some good time on it.", 
            "title": "Step 4: Optimize"
        }, 
        {
            "location": "/7_steps/#step-5-walk-through-your-algorithms", 
            "text": "Know exactly what you're going to do before coding    what variables   data structures?  how, why, why do they change?  what is the structure of your code   Then once you have an optimal algorithm or you're ready to start coding take a step back and just make sure you  know exactly  what you're going to do in your code.  So many people code prematurely when they aren't really really comfortable with what they're about to do and it ends in disaster. An eighty percent understanding of what you're about to write is really not enough for a whiteboard especially. So take a moment and walk through your algorithm and make sure you know exactly what you're about to do.", 
            "title": "Step 5: Walk through your algorithms"
        }, 
        {
            "location": "/7_steps/#step-6-code", 
            "text": "Use space wisely, coding style matters, modularize   Step 6 is to start coding and I'm gonna go into this in a bit of detail. So a couple things to keep in mind particularly when you're coding on a whiteboard. The first couple tips are kind of whiteboard specific but try to write your lines straight. I'm not gonna be judging you on your handwriting and things like that but when people start writing their lines and sharp angles they start to lose track over whether this if statement under this for loop or not. The second thing is use your board space wisely. If you don't need stuff up on the board anymore just erase it. Try to write in this top left corner etc.  Basically give yourself as much space as you possibly can to write your code. If you do run out of space though, it's ok to use arrows, that's fine, I'm really not gonna be judging you on this kind of stuff. So more important things.  Coding style matters  ( consistent braces ,  consistent variable naming ,  consistence spaces ,  descriptive variables )  Coding style matters even on a whiteboard but on a computer as well, so that means things like braces, naming conventions, or using camel case or underscores, things like that. Those kind of style things absolutely matter. I'm not that concerned over which style you pick, I don't care if you write braces on the same line or the next line but I do care a lot that you have a style and you stick to it. So be consistent in your style. When it comes to variable names, yeah I know it's an annoying to write long variable names on a whiteboard but descriptive variable names are important to good style. So one compromise here is write the good descriptive variable name first and then just ask your interviewer, hey is it okay if I abbreviate this the next time. So that'll be a nice little compromise - you'd show that you care about good variable names but you also don't waste a lot of time.  Modularize  ( before. not after )  Last thing I want to talk about is modularization. Modularize your code up front and just any little conceptual chunks of code, push that off to another function. So suppose you have three steps in your algorithm - process the first string, process the second string,  and then compare the results. Don't start writing these for loops that walk through each string in the very beginning. Instead write this overall function that wraps these three steps. So step one, step two, step three, and then start drilling in and going into all the details there. Remember any conceptual chunks of code push those off to other functions, don't write them in line.", 
            "title": "Step 6: Code"
        }, 
        {
            "location": "/7_steps/#step-7-test", 
            "text": "Analyse: think about each line, double check things that look weired/risky (for-loop that decrement, math)   Use test cases (smaller test-cases first (faster to run, you will problably be more through, edge cases, big test cases)   Then once you're done with the coding you have to start testing your code. One of the mistakes a lot of people do here is they take their big example from step 2 and throw that in as a test case. The problem with that is it's very large so it will take you a long time to run through but also you just used that to develop your code, so if here's an oversight there, the problem will probably repeat itself here.   What's a better step to do, what's a better process to do, is just walk through your code line by line and just think about each line up front not with the test case but just consider, is it really doing the right thing?  Double check anything that looks weird, so for loops that decrement instead of increment and any math at all is a really common place for errors. Just think, look at your code analytically and think what are the most likely places for errors to be and double-check those.  Start with small rather than big  Then once you start with actual test cases start with small test cases rather than big ones. Small test cases work pretty much as effectively as big test cases but they are so much faster to run through, and in fact because they're faster people tend to be much more thorough so you're much more likely to actually find bugs with small test cases than big test cases. So start with small test cases then go in to edge cases after that and then if you have time maybe throw in some big test cases. A couple last techniques with testing. The first one is make sure that when you're testing you're really thinking about what you're doing. A lot of people when they're testing they're just walking through their code almost like they're a bot, and they only look to see if things made sense at the very end when they look at their output. It's much better to really think as you're testing, this way you find the bug as soon as it happens rather than six lines later at the very bottom.  Test your code not your algorithm  The second thing is when you're testing make sure that you're actually testing your code and not your algorithm. An amazing number of people will just take their example and like just walk through it again as though they're just walking through their algorithm but they're never even looking at their code, they're not looking at the exact calculations their code actually did. So make sure that you're really testing your code.  Find bugs  Then the last thing is when you find in a bug, don't panic. Just really think about what caused the bug. A lot of times people will panic and just try to make the first fix that fixes it for that output but they haven't really given it some thought and then they're in a much worse position because if you make the wrong fix to your code, the thing that just fixed the output but didn't fix a real bug you've not fixed the actual bug, you've made your code more complex, and you potentially introduced a brand new bug and you're in a much worse position. It's much better to just when you find the bug, it's ok, it's not that big of a deal to have a bug it's very normal just really think through what the actual bug, where the actual plug came from.  Remember   think as you test (don't be a bot)  test your code, not your algorithm  think before you fix bugs. Don't panic! (wrong fixes are worse than no fix)", 
            "title": "Step 7: Test"
        }, 
        {
            "location": "/7_steps/#suggested-reading", 
            "text": "7 Steps to Solve Algorithm Problems. Gayle Laakmann McDowell", 
            "title": "Suggested Reading"
        }, 
        {
            "location": "/ds_array/", 
            "text": "Arrays\n\n\nAn array is an aggregate data structure that is designed to store a group of objects of the same or different types. Arrays can hold primitives as well as references. The array is the most efficient data structure for storing and accessing a sequence of objects.\n\n\nHere is the list of most important array features you must know (i.e. be able to program)\n\n\n\n\ncopying and cloning\n\n\ninsertion and deletion\n\n\nsearching and sorting\n\n\n\n\nYou already know that the Java language has only two data types, primitives and references. Which one is an array? Is it primitive? An array is not a primitive data type - it has a field (and only one), called length. Formally speaking, an array is a reference type, though you cannot find such a class in the Java APIs. Therefore, you deal with arrays as you deal with references. One of the major diffeences between refeences and primituives is that you cannot copy arrays by assigning one to another:\n\n\nint[] a = {9, 5, 4};\nint[] b = a;\n\n\n\n\nThe assignment operator creates an alias to the object, like in the picture below\n\n\n\n\nSince these two references a and b refer to the same object, comparing them with the double equal sign \"==\" will always return true. In the next code example,\n\n\nint [] a = {1,2,3};\nint [] b = {1,2,3};\n\n\n\n\na and b refer to two different objects (though with identical contents). Comparing them with the double equal sign will return false. How would you compare two objects with identical contents? In short, using the equals method. For array comparison, the Java APIs provides the Arrays class.\n\n\nThe Arrays class\n\n\nThe java.util.Arrays class is a convenience class for various array manipulations, like comparison, searching, printing, sorting and others. Basically, this class is a set of static methods that are all useful for working with arrays. The code below demonstrates a proper invocation of equals:\n\n\nint[] a = {1,2,3};\nint[] b = {1,2,3};\nif( Arrays.equals(a, b) )\n   System.out.println(\narrays with identical contents\n);\n\n\n\n\nAnother commonly used method is toString() which takes care of of printing\n\n\nint[] a = {1,2,3};\nSystem.out.println(Arrays.toString(a));\n\n\n\n\nHere is the example of sorting\n\n\nint[] a = {3,2,1};\nArrays.sort(a);\nSystem.out.println(Arrays.toString(a));\n\n\n\n\nIn addition to that, the class has other utility methods for supporting operations over multidimensional arrays.\n\n\nCopying arrays\n\n\nThere are four ways to copy arrays\n\n\nusing a loop structure\nusing Arrays.copyOf()\nusing System.arraycopy()\nusing clone()\nThe first way is very well known to you\n\n\nint[] a = {1, 2, 3};\nint[] b = new int[a.length];\nfor(int i= 0; i \n a.length; i++) b[i] = a[i];\n\n\n\n\nThe next choice is to use Arrays.copyOf()\n\n\nint[] a = {1, 2, 3};\nint[] b = Arrays.copyOf(a, a.length);\n\n\n\n\nThe second parameter specifies the length of the new array, which could either less or equal or bigger than the original length.\n\n\nThe most efficient copying data between arrays is provided by System.arraycopy() method. The method requires five arguments. Here is its signature\n\n\npublic static void arraycopy(Object source,\n                             int srcIndex,\n                             Object destination,\n                             int destIndex,\n                             int length)\n\n\n\n\nThe method copies length elements from a source array starting with the index srcIndex to a new array destination at the index destIndex.The above code example can be rewritten as it follows\n\n\nint[] a = {1, 2, 3};\nint[] b = new int[a.length];\nSystem.arraycopy(a, 0, b, 0, 3)\n\n\n\n\nAnd the last copying choice is the use of cloning. Cloning involves creating a new array of the same size and type and copying all the old elements into the new array. The clone() method is defined in the Object class and its invocation is demonstrated by this code segment\n\n\nint[] a = {1, 2, 3};\nint[] b = (int[]) a.clone();\n\n\n\n\nNote, that casting (int[]) is the must.\n\n\nExamine the code in ArrayCopyPrimitives.java for further details.\n\n\nInsertion and Deletion\n\n\nArrays in Java have no methods and only one \nimmutable\n field \nlength\n. Once an array is created, its length is fixed and cannot be changed. What do you do to resize the array? You allocate the array with a different size and copy the contents of the old array to the new array. This code example demonstrates deletion from an array of primitives\n\n\npublic char[] delete(char[] data, int pos)\n{\n    if(pos \n= 0 \n pos \n data.length)\n    {\n        char[] tmp = new char[data.length-1];\n        System.arraycopy(data, 0, tmp, 0, pos);\n        System.arraycopy(data, pos+1, tmp, pos, data.length-pos-1);\n        return tmp;\n    }\n    else\n        return data;\n}\n\n\n\n\nThe first arraycopy copies the elements from index 0 to index pos-1, the second arraycopy copies the elements from index pos+1 to data.length.\n\n\nExamine the code in ArrayDemo.java for further details.\n\n\nThe ArrayList class\n\n\nThe java.util.ArrayList class supports an idea of a dynamic array - an array that grows and shrinks on demand to accomodate the number of elements in the array. Below is a list of commonly used methods\n\n\n\n\nadd(object)\n - adds to the end\n\n\nadd(index, object)\n - inserts at the index\n\n\nset(index, object)\n - replaces at the index\n\n\nget(index)\n - returns the element at that index\n\n\nremove(index)\n - deletes the element at that index\n\n\nsize()\n - returns the number of elements\n\n\n\n\nThe following code example will give you a heads up into how some of them are used.\n\n\n/* ADD */\n      ArrayList\nInteger\n num = new ArrayList\nInteger\n();\n      for(int i = 0; i \n 10; i++) num.add(i);\n      System.out.println(num);\n\n\n/* REMOVE even integers */\n      for(int i = 0; i \n num.size(); i++)\n        if(num.get(i)%2 == 0) num.remove(i);\n      System.out.println(num);\n\n\n\n\nCopying arrays of objects\n\n\nThis topic is more complex for understanding.. Let us start with a simple loop structure\n\n\nObject[] obj1 = {new Integer(10),\n                new StringBuffer(\nfoobar\n),\n                new Double(12.95)};\nObject[] obj2 = new Object[obj1.length];\nfor(int i = 0; i \u2039 obj1.length; i++)\n    obj2[i] = obj1[i];\n\n\n\n\nAt the first glance we might think that all data is copied. In reality, the internal data is shared between two arrays. The figure below illustrates the inner structure\n\n\n\n\nThe assignment operator \nobj2[i] = obj1[i]\n is a crucial part of understanding the concept. You cannot copy references by assigning one to another. The assignment creates an alias rather than a copy. Let us trace down changes in the above picture after execution the following statements\n\n\nobj1[0] = new Integer(5);\n\n\n\n\n\n\nand \n((StringBuffer) obj1[1]).append('s');\n\n\n\n\nAs you see, \nobj1[0]\n and \nobj2[0]\n now refer to different objects. However, \nobj1[1]\n and \nobj2[1]\n refer to the same object (which is \"foobars\"). Since both arrays shares the data, you must be quite careful when you modify your data, because it might lead to unexpected effects.\n\n\nThe same behavior will take place again, if we use Arrays.copuyOf(), System.arraycopy() and clone(). Examine the code example ArrayCopyReferences.java for further details.\n\n\nMulti-dimensional arrays\n\n\nIn many practical application there is a need to use two- or multi-dimensional arrays. A two-dimensional array can be thought of as a table of rows and columns. This creates a table of 2 rows and 4 columns:\n\n\nint[][] ar1 = new int[2][4];\n\n\n\n\nYou can create and initialize an array by using nested curcly braces. For example, this creates a table of 3 rows and 2 columns:\n\n\nint[][] ar2 = {{1,2},{3,4},{5,6}};\n\n\n\n\nGenerally speaking, a two-dimensional array is not exactly a table - each row in such array can have a different length. Consider this code fragment\n\n\nObject[][] obj = {{new Integer(1),new Integer(2)},\n                  {new Integer(10), \nbozo\n, new Double(1.95)}};\n\n\n\n\nThe accompanying picture sheds a bit of light on internal representation\n\n\n\n\nFrom the picture you clearly see that a two-dimensional array in Java is an array of arrays. The array obj has two elements obj[0] and obj[1] that are arrays of length 2 and 3 respectively.\n\n\nCloning 2D arrays\n\n\nThe procedure is even more confusing and less expected. Consider the following code segment\n\n\nObject[][] obj = {{new Integer(1),new Integer(2)},\n                  {new Integer(10), \nbozo\n, new Double(1.95)}};\n\nObject[][] twin = (Object[][]) obj.clone();\n\n\n\n\nThe procedure of clonig 2d arrays is virtually the same as cloning an array of references. Unfortunately, built-in clone() method does not actualy clone each row, but rather creates references to them Here is a graphical interpretation of the above code\n\n\n\n\nLet us change the value of \nobj[1][1]\n\n\nobj[1][1] = \nxyz\n;\n\n\n\n\nThis assignment effects the value of \ntwin[1][1]\n as well\n\n\n\n\nSuch a copy is called a \"shallow\" copy. The default behavior of clone() is to return a shallow copy of the object. If we want a \"deep\" copy instead, we must provide our own implementation by overriding Object's clone() method.\n\n\nThe idea of a \"deep\" copy is simple - it makes a distinct copy of each of the object's fields, recursing through the entire object. A deep copy is thus a completely separate object from the original; changes to it don't affect the original, and vise versa. In relevance to the above code, here is a deep clone graphically\n\n\n\n\nFurther, making a complete deep copy is not always needed. Consider an array of immutable objects. As we know, immutable objects cannot be modified, allowing clients to share the same instance without interfering with each other. In this case there is no need to clone them, which leads to the following picture\n\n\n\n\nAlways in this course we will create data structures of immutable objets, therefore implementing the clone method will require copying a structure (a shape) and sharing its internal data. We will discuss these issues later on in the course.\n\n\nChallenges\n\n\n\n\n\"Arrays: Left Rotation\". \nhackerrank\n. 2016\n\n\n\n\nReferences\n\n\n\n\n\"Array Data Structure\". \nVictor S.Adamchik, CMU\n. 2009", 
            "title": "Arrays"
        }, 
        {
            "location": "/ds_array/#arrays", 
            "text": "An array is an aggregate data structure that is designed to store a group of objects of the same or different types. Arrays can hold primitives as well as references. The array is the most efficient data structure for storing and accessing a sequence of objects.  Here is the list of most important array features you must know (i.e. be able to program)   copying and cloning  insertion and deletion  searching and sorting   You already know that the Java language has only two data types, primitives and references. Which one is an array? Is it primitive? An array is not a primitive data type - it has a field (and only one), called length. Formally speaking, an array is a reference type, though you cannot find such a class in the Java APIs. Therefore, you deal with arrays as you deal with references. One of the major diffeences between refeences and primituives is that you cannot copy arrays by assigning one to another:  int[] a = {9, 5, 4};\nint[] b = a;  The assignment operator creates an alias to the object, like in the picture below   Since these two references a and b refer to the same object, comparing them with the double equal sign \"==\" will always return true. In the next code example,  int [] a = {1,2,3};\nint [] b = {1,2,3};  a and b refer to two different objects (though with identical contents). Comparing them with the double equal sign will return false. How would you compare two objects with identical contents? In short, using the equals method. For array comparison, the Java APIs provides the Arrays class.", 
            "title": "Arrays"
        }, 
        {
            "location": "/ds_array/#the-arrays-class", 
            "text": "The java.util.Arrays class is a convenience class for various array manipulations, like comparison, searching, printing, sorting and others. Basically, this class is a set of static methods that are all useful for working with arrays. The code below demonstrates a proper invocation of equals:  int[] a = {1,2,3};\nint[] b = {1,2,3};\nif( Arrays.equals(a, b) )\n   System.out.println( arrays with identical contents );  Another commonly used method is toString() which takes care of of printing  int[] a = {1,2,3};\nSystem.out.println(Arrays.toString(a));  Here is the example of sorting  int[] a = {3,2,1};\nArrays.sort(a);\nSystem.out.println(Arrays.toString(a));  In addition to that, the class has other utility methods for supporting operations over multidimensional arrays.", 
            "title": "The Arrays class"
        }, 
        {
            "location": "/ds_array/#copying-arrays", 
            "text": "There are four ways to copy arrays  using a loop structure\nusing Arrays.copyOf()\nusing System.arraycopy()\nusing clone()\nThe first way is very well known to you  int[] a = {1, 2, 3};\nint[] b = new int[a.length];\nfor(int i= 0; i   a.length; i++) b[i] = a[i];  The next choice is to use Arrays.copyOf()  int[] a = {1, 2, 3};\nint[] b = Arrays.copyOf(a, a.length);  The second parameter specifies the length of the new array, which could either less or equal or bigger than the original length.  The most efficient copying data between arrays is provided by System.arraycopy() method. The method requires five arguments. Here is its signature  public static void arraycopy(Object source,\n                             int srcIndex,\n                             Object destination,\n                             int destIndex,\n                             int length)  The method copies length elements from a source array starting with the index srcIndex to a new array destination at the index destIndex.The above code example can be rewritten as it follows  int[] a = {1, 2, 3};\nint[] b = new int[a.length];\nSystem.arraycopy(a, 0, b, 0, 3)  And the last copying choice is the use of cloning. Cloning involves creating a new array of the same size and type and copying all the old elements into the new array. The clone() method is defined in the Object class and its invocation is demonstrated by this code segment  int[] a = {1, 2, 3};\nint[] b = (int[]) a.clone();  Note, that casting (int[]) is the must.  Examine the code in ArrayCopyPrimitives.java for further details.", 
            "title": "Copying arrays"
        }, 
        {
            "location": "/ds_array/#insertion-and-deletion", 
            "text": "Arrays in Java have no methods and only one  immutable  field  length . Once an array is created, its length is fixed and cannot be changed. What do you do to resize the array? You allocate the array with a different size and copy the contents of the old array to the new array. This code example demonstrates deletion from an array of primitives  public char[] delete(char[] data, int pos)\n{\n    if(pos  = 0   pos   data.length)\n    {\n        char[] tmp = new char[data.length-1];\n        System.arraycopy(data, 0, tmp, 0, pos);\n        System.arraycopy(data, pos+1, tmp, pos, data.length-pos-1);\n        return tmp;\n    }\n    else\n        return data;\n}  The first arraycopy copies the elements from index 0 to index pos-1, the second arraycopy copies the elements from index pos+1 to data.length.  Examine the code in ArrayDemo.java for further details.", 
            "title": "Insertion and Deletion"
        }, 
        {
            "location": "/ds_array/#the-arraylist-class", 
            "text": "The java.util.ArrayList class supports an idea of a dynamic array - an array that grows and shrinks on demand to accomodate the number of elements in the array. Below is a list of commonly used methods   add(object)  - adds to the end  add(index, object)  - inserts at the index  set(index, object)  - replaces at the index  get(index)  - returns the element at that index  remove(index)  - deletes the element at that index  size()  - returns the number of elements   The following code example will give you a heads up into how some of them are used.  /* ADD */\n      ArrayList Integer  num = new ArrayList Integer ();\n      for(int i = 0; i   10; i++) num.add(i);\n      System.out.println(num);\n\n\n/* REMOVE even integers */\n      for(int i = 0; i   num.size(); i++)\n        if(num.get(i)%2 == 0) num.remove(i);\n      System.out.println(num);", 
            "title": "The ArrayList class"
        }, 
        {
            "location": "/ds_array/#copying-arrays-of-objects", 
            "text": "This topic is more complex for understanding.. Let us start with a simple loop structure  Object[] obj1 = {new Integer(10),\n                new StringBuffer( foobar ),\n                new Double(12.95)};\nObject[] obj2 = new Object[obj1.length];\nfor(int i = 0; i \u2039 obj1.length; i++)\n    obj2[i] = obj1[i];  At the first glance we might think that all data is copied. In reality, the internal data is shared between two arrays. The figure below illustrates the inner structure   The assignment operator  obj2[i] = obj1[i]  is a crucial part of understanding the concept. You cannot copy references by assigning one to another. The assignment creates an alias rather than a copy. Let us trace down changes in the above picture after execution the following statements  obj1[0] = new Integer(5);   and  ((StringBuffer) obj1[1]).append('s');   As you see,  obj1[0]  and  obj2[0]  now refer to different objects. However,  obj1[1]  and  obj2[1]  refer to the same object (which is \"foobars\"). Since both arrays shares the data, you must be quite careful when you modify your data, because it might lead to unexpected effects.  The same behavior will take place again, if we use Arrays.copuyOf(), System.arraycopy() and clone(). Examine the code example ArrayCopyReferences.java for further details.", 
            "title": "Copying arrays of objects"
        }, 
        {
            "location": "/ds_array/#multi-dimensional-arrays", 
            "text": "In many practical application there is a need to use two- or multi-dimensional arrays. A two-dimensional array can be thought of as a table of rows and columns. This creates a table of 2 rows and 4 columns:  int[][] ar1 = new int[2][4];  You can create and initialize an array by using nested curcly braces. For example, this creates a table of 3 rows and 2 columns:  int[][] ar2 = {{1,2},{3,4},{5,6}};  Generally speaking, a two-dimensional array is not exactly a table - each row in such array can have a different length. Consider this code fragment  Object[][] obj = {{new Integer(1),new Integer(2)},\n                  {new Integer(10),  bozo , new Double(1.95)}};  The accompanying picture sheds a bit of light on internal representation   From the picture you clearly see that a two-dimensional array in Java is an array of arrays. The array obj has two elements obj[0] and obj[1] that are arrays of length 2 and 3 respectively.", 
            "title": "Multi-dimensional arrays"
        }, 
        {
            "location": "/ds_array/#cloning-2d-arrays", 
            "text": "The procedure is even more confusing and less expected. Consider the following code segment  Object[][] obj = {{new Integer(1),new Integer(2)},\n                  {new Integer(10),  bozo , new Double(1.95)}};\n\nObject[][] twin = (Object[][]) obj.clone();  The procedure of clonig 2d arrays is virtually the same as cloning an array of references. Unfortunately, built-in clone() method does not actualy clone each row, but rather creates references to them Here is a graphical interpretation of the above code   Let us change the value of  obj[1][1]  obj[1][1] =  xyz ;  This assignment effects the value of  twin[1][1]  as well   Such a copy is called a \"shallow\" copy. The default behavior of clone() is to return a shallow copy of the object. If we want a \"deep\" copy instead, we must provide our own implementation by overriding Object's clone() method.  The idea of a \"deep\" copy is simple - it makes a distinct copy of each of the object's fields, recursing through the entire object. A deep copy is thus a completely separate object from the original; changes to it don't affect the original, and vise versa. In relevance to the above code, here is a deep clone graphically   Further, making a complete deep copy is not always needed. Consider an array of immutable objects. As we know, immutable objects cannot be modified, allowing clients to share the same instance without interfering with each other. In this case there is no need to clone them, which leads to the following picture   Always in this course we will create data structures of immutable objets, therefore implementing the clone method will require copying a structure (a shape) and sharing its internal data. We will discuss these issues later on in the course.", 
            "title": "Cloning 2D arrays"
        }, 
        {
            "location": "/ds_array/#challenges", 
            "text": "\"Arrays: Left Rotation\".  hackerrank . 2016", 
            "title": "Challenges"
        }, 
        {
            "location": "/ds_array/#references", 
            "text": "\"Array Data Structure\".  Victor S.Adamchik, CMU . 2009", 
            "title": "References"
        }, 
        {
            "location": "/ds_linked_list/", 
            "text": "Linked List\n\n\nA linked list is a sequence of data structures, which are connected together via links.\n\n\nLinked List is a sequence of links which contains items. Each link contains a connection to another link. Linked list is the second most-used data structure after array. Following are the important terms to understand the concept of Linked List.\n\n\n\n\nLink \u2212 Each link of a linked list can store a data called an element.\n\n\nNext \u2212 Each link of a linked list contains a link to the next link called Next.\n\n\nLinkedList \u2212 A Linked List contains the connection link to the first link called First.\n\n\n\n\nRepresentation\n\n\nLinked list can be visualized as a chain of nodes, where every node points to the next node.\n\n\n\n\nAs per the above illustration, following are the important points to be considered.\n\n\n\n\nLinked List contains a link element called first.\n\n\nEach link carries a data field(s) and a link field called next.\n\n\nEach link is linked with its next link using its next link.\n\n\nLast link carries a link as null to mark the end of the list.\n\n\n\n\nTypes of Linked List\n\n\nFollowing are the various types of linked list.\n\n\n\n\nSimple Linked List \u2212 Item navigation is forward only.\n\n\nDoubly Linked List \u2212 Items can be navigated forward and backward.\n\n\nCircular Linked List \u2212 Last item contains link of the first element as next and the first element has a link to the last element as previous.\n\n\n\n\nBasic Operations\n\n\nFollowing are the basic operations supported by a list.\n\n\n\n\nInsertion \u2212 Adds an element at the beginning of the list.\n\n\nDeletion \u2212 Deletes an element at the beginning of the list.\n\n\nDisplay \u2212 Displays the complete list.\n\n\nSearch \u2212 Searches an element using the given key.\n\n\nDelete \u2212 Deletes an element using the given key.\n\n\n\n\nInsertion Operation\n\n\nAdding a new node in linked list is a more than one step activity. We shall learn this with diagrams here. First, create a node using the same structure and find the location where it has to be inserted.\n\n\n\n\nImagine that we are inserting a node B (NewNode), between A (LeftNode) and C (RightNode). Then point B.next to C\n\n\nNewNode.next \u2212\n RightNode;\n\n\n\n\nIt should look like this\n\n\n\n\nNow, the next node at the left should point to the new node.\n\n\nLeftNode.next \u2212\n NewNode;\n\n\n\n\n\n\nThis will put the new node in the middle of the two. The new list should look like this\n\n\n\n\nSimilar steps should be taken if the node is being inserted at the beginning of the list. While inserting it at the end, the second last node of the list should point to the new node and the new node will point to NULL.\n\n\nDeletion Operation\n\n\nDeletion is also a more than one step process. We shall learn with pictorial representation. First, locate the target node to be removed, by using searching algorithms.\n\n\n\n\nThe left (previous) node of the target node now should point to the next node of the target node\n\n\nLeftNode.next \u2212\n TargetNode.next;\n\n\n\n\n\n\nThis will remove the link that was pointing to the target node. Now, using the following code, we will remove what the target node is pointing at.\n\n\nTargetNode.next \u2212\n NULL;\n\n\n\n\n\n\nWe need to use the deleted node. We can keep that in memory otherwise we can simply deallocate memory and wipe off the target node completely.\n\n\nReverse Operation\n\n\nThis operation is a thorough one. We need to make the last node to be pointed by the head node and reverse the whole linked list.\n\n\n\n\nFirst, we traverse to the end of the list. It should be pointing to NULL. Now, we shall make it point to its previous node\n\n\n\n\nWe have to make sure that the last node is not the lost node. So we'll have some temp node, which looks like the head node pointing to the last node. Now, we shall make all left side nodes point to their previous nodes one by one.\n\n\n\n\nExcept the node (first node) pointed by the head node, all nodes should point to their predecessor, making them their new successor. The first node will point to NULL.\n\n\n\n\nWe'll make the head node point to the new first node by using the temp node.\n\n\n\n\nThe linked list is now reversed.", 
            "title": "Linked List"
        }, 
        {
            "location": "/ds_linked_list/#linked-list", 
            "text": "A linked list is a sequence of data structures, which are connected together via links.  Linked List is a sequence of links which contains items. Each link contains a connection to another link. Linked list is the second most-used data structure after array. Following are the important terms to understand the concept of Linked List.   Link \u2212 Each link of a linked list can store a data called an element.  Next \u2212 Each link of a linked list contains a link to the next link called Next.  LinkedList \u2212 A Linked List contains the connection link to the first link called First.", 
            "title": "Linked List"
        }, 
        {
            "location": "/ds_linked_list/#representation", 
            "text": "Linked list can be visualized as a chain of nodes, where every node points to the next node.   As per the above illustration, following are the important points to be considered.   Linked List contains a link element called first.  Each link carries a data field(s) and a link field called next.  Each link is linked with its next link using its next link.  Last link carries a link as null to mark the end of the list.", 
            "title": "Representation"
        }, 
        {
            "location": "/ds_linked_list/#types-of-linked-list", 
            "text": "Following are the various types of linked list.   Simple Linked List \u2212 Item navigation is forward only.  Doubly Linked List \u2212 Items can be navigated forward and backward.  Circular Linked List \u2212 Last item contains link of the first element as next and the first element has a link to the last element as previous.", 
            "title": "Types of Linked List"
        }, 
        {
            "location": "/ds_linked_list/#basic-operations", 
            "text": "Following are the basic operations supported by a list.   Insertion \u2212 Adds an element at the beginning of the list.  Deletion \u2212 Deletes an element at the beginning of the list.  Display \u2212 Displays the complete list.  Search \u2212 Searches an element using the given key.  Delete \u2212 Deletes an element using the given key.", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/ds_linked_list/#insertion-operation", 
            "text": "Adding a new node in linked list is a more than one step activity. We shall learn this with diagrams here. First, create a node using the same structure and find the location where it has to be inserted.   Imagine that we are inserting a node B (NewNode), between A (LeftNode) and C (RightNode). Then point B.next to C  NewNode.next \u2212  RightNode;  It should look like this   Now, the next node at the left should point to the new node.  LeftNode.next \u2212  NewNode;   This will put the new node in the middle of the two. The new list should look like this   Similar steps should be taken if the node is being inserted at the beginning of the list. While inserting it at the end, the second last node of the list should point to the new node and the new node will point to NULL.", 
            "title": "Insertion Operation"
        }, 
        {
            "location": "/ds_linked_list/#deletion-operation", 
            "text": "Deletion is also a more than one step process. We shall learn with pictorial representation. First, locate the target node to be removed, by using searching algorithms.   The left (previous) node of the target node now should point to the next node of the target node  LeftNode.next \u2212  TargetNode.next;   This will remove the link that was pointing to the target node. Now, using the following code, we will remove what the target node is pointing at.  TargetNode.next \u2212  NULL;   We need to use the deleted node. We can keep that in memory otherwise we can simply deallocate memory and wipe off the target node completely.", 
            "title": "Deletion Operation"
        }, 
        {
            "location": "/ds_linked_list/#reverse-operation", 
            "text": "This operation is a thorough one. We need to make the last node to be pointed by the head node and reverse the whole linked list.   First, we traverse to the end of the list. It should be pointing to NULL. Now, we shall make it point to its previous node   We have to make sure that the last node is not the lost node. So we'll have some temp node, which looks like the head node pointing to the last node. Now, we shall make all left side nodes point to their previous nodes one by one.   Except the node (first node) pointed by the head node, all nodes should point to their predecessor, making them their new successor. The first node will point to NULL.   We'll make the head node point to the new first node by using the temp node.   The linked list is now reversed.", 
            "title": "Reverse Operation"
        }, 
        {
            "location": "/ds_stack_queue/", 
            "text": "Stacks and Queues\n\n\nAn array is a random access data structure, where each element can be accessed directly and in constant time. A typical illustration of random access is a book - each page of the book can be open independently of others. Random access is critical to many algorithms, for example binary search.\n\n\nA linked list is a sequential access data structure, where each element can be accesed only in particular order. A typical illustration of sequential access is a roll of paper or tape - all prior material must be unrolled in order to get to data you want.\n\n\nIn this note we consider a subcase of sequential data structures, so-called limited access data sturctures.\n\n\nStacks\n\n\nA stack is a container of objects that are inserted and removed according to the last-in first-out (LIFO) principle. In the pushdown stacks only two operations are allowed: push the item into the stack, and pop the item out of the stack. A stack is a limited access data structure - elements can be added and removed from the stack only at the top. push adds an item to the top of the stack, pop removes the item from the top. A helpful analogy is to think of a stack of books; you can remove only the top book, also you can add a new book on the top.\nA stack is a recursive data structure. Here is a structural definition of a Stack:\n\n\n\n\na stack is either empty or\n\n\nit consistes of a top and the rest which is a stack;\n\n\n\n\n\n\nApplications\n\n\n\n\nThe simplest application of a stack is to reverse a word. You push a given word to stack - letter by letter - and then pop letters from the stack.\n\n\nAnother application is an \"undo\" mechanism in text editors; this operation is accomplished by keeping all text changes in a stack.\n\n\nBacktracking\n. This is a process when you need to access the most recent data element in a series of elements. Think of a labyrinth or maze - how do you find a way from an entrance to an exit?\nOnce you reach a dead end, you must backtrack. But backtrack to where? to the previous choice point. Therefore, at each choice point you store on a stack all possible choices. Then backtracking simply means popping a next choice from the stack.\n\n\n\n\n\n\n\n\nLanguage processing:\n\n\nspace for parameters and local variables is created internally using a stack.\n\n\ncompiler's syntax check for matching braces is implemented by using stack.\n\n\nsupport for recursion\n\n\n\n\n\n\n\n\nImplementation\n\n\nIn the standard library of classes, the data type stack is an adapter class, meaning that a stack is built on top of other data structures. The underlying structure for a stack could be an array, a vector, an ArrayList, a linked list, or any other collection. Regardless of the type of the underlying data structure, a Stack must implement the same functionality. This is achieved by providing a unique interface:\n\n\npublic interface StackInterface\nAnyType\n\n{\n   public void push(AnyType e);\n\n   public AnyType pop();\n\n   public AnyType peek();\n\n   public boolean isEmpty();\n}\n\n\n\n\nThe following picture demonstrates the idea of implementation by composition.\n\n\n\n\nAnother implementation requirement (in addition to the above interface) is that all stack operations must run in constant time O(1). Constant time means that there is some constant k such that an operation takes k nanoseconds of computational time regardless of the stack size.\n\n\nArray-based implementation\n\n\n\n\nIn an array-based implementation we maintain the following fields: an array A of a default size (\u2265 1), the variable top that refers to the top element in the stack and the capacity that refers to the array size. The variable top changes from -1 to capacity - 1. We say that a stack is empty when top = -1, and the stack is full when top = capacity-1.\nIn a fixed-size stack abstraction, the capacity stays unchanged, therefore when top reaches capacity, the stack object throws an exception. See ArrayStack.java for a complete implementation of the stack class.\n\n\nIn a dynamic stack abstraction when top reaches capacity, we double up the stack siz\n\n\nLinked List-based implementation\n\n\n\n\nLinked List-based implementation provides the best (from the efficiency point of view) dynamic stack implementation.\nSee ListStack.java for a complete implementation of the stack class.\n\n\nQueues\n\n\nA queue is a container of objects (a linear collection) that are inserted and removed according to the first-in first-out (FIFO) principle. An excellent example of a queue is a line of students in the food court of the UC. New additions to a line made to the back of the queue, while removal (or serving) happens in the front. In the queue only two operations are allowed enqueue and dequeue. Enqueue means to insert an item into the back of the queue, dequeue means removing the front item. The picture demonstrates the FIFO access.\nThe difference between stacks and queues is in removing. In a stack we remove the item the most recently added; in a queue, we remove the item the least recently added.\n\n\n\n\nImplementation\n\n\nIn the standard library of classes, the data type queue is an adapter class, meaning that a queue is built on top of other data structures. The underlying structure for a queue could be an array, a Vector, an ArrayList, a LinkedList, or any other collection. Regardless of the type of the underlying data structure, a queue must implement the same functionality. This is achieved by providing a unique interface.\n\n\ninterface QueueInterface\u2039AnyType\n\n{\n   public boolean isEmpty();\n\n   public AnyType getFront();\n\n   public AnyType dequeue();\n\n   public void enqueue(AnyType e);\n\n   public void clear();\n}\n\n\n\n\nEach of the above basic operations must run at constant time O(1). The following picture demonstrates the idea of implementation by composition.\n\n\n\n\nCircular Queue\n\n\nGiven an array A of a default size (\u2265 1) with two references back and front, originally set to -1 and 0 respectively. Each time we insert (enqueue) a new item, we increase the back index; when we remove (dequeue) an item - we increase the front index. Here is a picture that illustrates the model after a few steps:\n\n\n\n\nAs you see from the picture, the queue logically moves in the array from left to right. After several moves back reaches the end, leaving no space for adding new elements\n\n\n\n\nHowever, there is a free space before the front index. We shall use that space for enqueueing new items, i.e. the next entry will be stored at index 0, then 1, until front. Such a model is called a wrap around queue or a circular queue\n\n\n\n\nFinally, when back reaches front, the queue is full. There are two choices to handle a full queue:a) throw an exception; b) double the array size.\n\n\nThe circular queue implementation is done by using the modulo operator (denoted %), which is computed by taking the remainder of division (for example, 8%5 is 3). By using the modulo operator, we can view the queue as a circular array, where the \"wrapped around\" can be simulated as \"back % array_size\". In addition to the back and front indexes, we maintain another index: cur - for counting the number of elements in a queue. Having this index simplifies a logic of implementation.\n\n\nSee ArrayQueue.java for a complete implementation of a circular queue.\n\n\nApplications\n\n\nThe simplest two search techniques are known as Depth-First Search(DFS) and Breadth-First Search (BFS). These two searches are described by looking at how the search tree (representing all the possible paths from the start) will be traversed.\n\n\nDeapth-First Search with a Stack\n\n\nIn depth-first search we go down a path until we get to a dead end; then we backtrack or back up (by popping a stack) to get an alternative path.\n\n\nCreate a stack\nCreate a new choice point\nPush the choice point onto the stack\nwhile (not found and stack is not empty)\n    Pop the stack\n    Find all possible choices after the last one tried\n    Push these choices onto the stack\nReturn\n\n\n\n\nBreadth-First Search with a Queue\n\n\nIn breadth-first search we explore all the nearest possibilities by finding all possible successors and enqueue them to a queue.\n\n\nCreate a queue\nCreate a new choice point\nEnqueue the choice point onto the queue\nwhile (not found and queue is not empty)\n    Dequeue the queue\n    Find all possible choices after the last one tried\n    Enqueue these choices onto the queue\nReturn\n\n\n\n\nWe will see more on search techniques later in the course.\n\n\nArithmetic Expression Evaluation\n\n\nAn important application of stacks is in parsing. For example, a compiler must parse arithmetic expressions written using infix notation:\n\n\n1 + ((2 + 3) * 4 + 5)*6\n\n\n\n\nWe break the problem of parsing infix expressions into two stages. First, we convert from infix to a different representation called postfix. Then we parse the postfix expression, which is a somewhat easier problem than directly parsing infix.\n\n\nConverting from Infix to Postfix.\n Typically, we deal with expressions in infix notation\n\n\n2 + 5\n\n\n\n\nwhere the operators (e.g. +, *) are written between the operands (e.q, 2 and 5). Writing the operators after the operands gives a postfix expression 2 and 5 are called operands, and the '+' is operator. The above arithmetic expression is called infix, since the operator is in between operands. The expression\n\n\n2 5 +\n\n\n\n\nWriting the operators before the operands gives a prefix expression\n\n\n+2 5\n\n\n\n\nSuppose you want to compute the cost of your shopping trip. To do so, you add a list of numbers and multiply them by the local sales tax (7.25%):\n\n\n70 + 150 * 1.0725\n\n\n\n\nDepending on the calculator, the answer would be either 235.95 or 230.875. To avoid this confusion we shall use a postfix notation\n\n\n70  150 + 1.0725 *\n\n\n\n\nPostfix has the nice property that parentheses are unnecessary.\n\n\nNow, we describe how to convert from infix to postfix.\n\n\n\n\nRead in the tokens one at a time\n\n\nIf a token is an integer, write it into the output\n\n\nIf a token is an operator, push it to the stack, if the stack is empty. If the stack is not empty, you pop entries with higher or equal priority and only then you push that 1. token to the stack.\n\n\nIf a token is a left parentheses '(', push it to the stack\n\n\nIf a token is a right parentheses ')', you pop entries until you meet '('.\n\n\nWhen you finish reading the string, you pop up all tokens which are left there.\n\n\nArithmetic precedence is in increasing order: '+', '-', '*', '/';\n\n\n\n\nExample. Suppose we have an infix expression:2+(4+3*2+1)/3. We read the string by characters.\n\n\n'2' - send to the output.\n'+' - push on the stack.\n'(' - push on the stack.\n'4' - send to the output.\n'+' - push on the stack.\n'3' - send to the output.\n'*' - push on the stack.\n'2' - send to the output.\n\n\n\n\nEvaluating a Postfix Expression\n. We describe how to parse and evaluate a postfix expression.\n\n\n\n\nWe read the tokens in one at a time.\n\n\nIf it is an integer, push it on the stack\n\n\nIf it is a binary operator, pop the top two elements from the stack, apply the operator, and push the result back on the stack.\n\n\n\n\nConsider the following postfix expression\n\n\n5 9 3 + 4 2 * * 7 + *\n\n\n\n\nHere is a chain of operations\n\n\nStack Operations              Output\n--------------------------------------\npush(5);                        5\npush(9);                        5 9\npush(3);                        5 9 3\npush(pop() + pop())             5 12\npush(4);                        5 12 4\npush(2);                        5 12 4 2\npush(pop() * pop())             5 12 8\npush(pop() * pop())             5 96\npush(7)                         5 96 7\npush(pop() + pop())             5 103\npush(pop() * pop())             515\n\n\n\n\nNote, that division is not a commutative operation, so 2/3 is not the same as 3/2.\n\n\nChallenges\n\n\n\n\nStacks: Balanced Brackets\n\n\nQueues: A Tale of Two Stacks\n\n\n\n\nReferences\n\n\n\n\n\"Stacks and Queues\". \nVictor S.Adamchik, CMU\n. 2009", 
            "title": "Stacks & Queues"
        }, 
        {
            "location": "/ds_stack_queue/#stacks-and-queues", 
            "text": "An array is a random access data structure, where each element can be accessed directly and in constant time. A typical illustration of random access is a book - each page of the book can be open independently of others. Random access is critical to many algorithms, for example binary search.  A linked list is a sequential access data structure, where each element can be accesed only in particular order. A typical illustration of sequential access is a roll of paper or tape - all prior material must be unrolled in order to get to data you want.  In this note we consider a subcase of sequential data structures, so-called limited access data sturctures.", 
            "title": "Stacks and Queues"
        }, 
        {
            "location": "/ds_stack_queue/#stacks", 
            "text": "A stack is a container of objects that are inserted and removed according to the last-in first-out (LIFO) principle. In the pushdown stacks only two operations are allowed: push the item into the stack, and pop the item out of the stack. A stack is a limited access data structure - elements can be added and removed from the stack only at the top. push adds an item to the top of the stack, pop removes the item from the top. A helpful analogy is to think of a stack of books; you can remove only the top book, also you can add a new book on the top.\nA stack is a recursive data structure. Here is a structural definition of a Stack:   a stack is either empty or  it consistes of a top and the rest which is a stack;", 
            "title": "Stacks"
        }, 
        {
            "location": "/ds_stack_queue/#applications", 
            "text": "The simplest application of a stack is to reverse a word. You push a given word to stack - letter by letter - and then pop letters from the stack.  Another application is an \"undo\" mechanism in text editors; this operation is accomplished by keeping all text changes in a stack.  Backtracking . This is a process when you need to access the most recent data element in a series of elements. Think of a labyrinth or maze - how do you find a way from an entrance to an exit?\nOnce you reach a dead end, you must backtrack. But backtrack to where? to the previous choice point. Therefore, at each choice point you store on a stack all possible choices. Then backtracking simply means popping a next choice from the stack.     Language processing:  space for parameters and local variables is created internally using a stack.  compiler's syntax check for matching braces is implemented by using stack.  support for recursion", 
            "title": "Applications"
        }, 
        {
            "location": "/ds_stack_queue/#implementation", 
            "text": "In the standard library of classes, the data type stack is an adapter class, meaning that a stack is built on top of other data structures. The underlying structure for a stack could be an array, a vector, an ArrayList, a linked list, or any other collection. Regardless of the type of the underlying data structure, a Stack must implement the same functionality. This is achieved by providing a unique interface:  public interface StackInterface AnyType \n{\n   public void push(AnyType e);\n\n   public AnyType pop();\n\n   public AnyType peek();\n\n   public boolean isEmpty();\n}  The following picture demonstrates the idea of implementation by composition.   Another implementation requirement (in addition to the above interface) is that all stack operations must run in constant time O(1). Constant time means that there is some constant k such that an operation takes k nanoseconds of computational time regardless of the stack size.", 
            "title": "Implementation"
        }, 
        {
            "location": "/ds_stack_queue/#array-based-implementation", 
            "text": "In an array-based implementation we maintain the following fields: an array A of a default size (\u2265 1), the variable top that refers to the top element in the stack and the capacity that refers to the array size. The variable top changes from -1 to capacity - 1. We say that a stack is empty when top = -1, and the stack is full when top = capacity-1.\nIn a fixed-size stack abstraction, the capacity stays unchanged, therefore when top reaches capacity, the stack object throws an exception. See ArrayStack.java for a complete implementation of the stack class.  In a dynamic stack abstraction when top reaches capacity, we double up the stack siz", 
            "title": "Array-based implementation"
        }, 
        {
            "location": "/ds_stack_queue/#linked-list-based-implementation", 
            "text": "Linked List-based implementation provides the best (from the efficiency point of view) dynamic stack implementation.\nSee ListStack.java for a complete implementation of the stack class.", 
            "title": "Linked List-based implementation"
        }, 
        {
            "location": "/ds_stack_queue/#queues", 
            "text": "A queue is a container of objects (a linear collection) that are inserted and removed according to the first-in first-out (FIFO) principle. An excellent example of a queue is a line of students in the food court of the UC. New additions to a line made to the back of the queue, while removal (or serving) happens in the front. In the queue only two operations are allowed enqueue and dequeue. Enqueue means to insert an item into the back of the queue, dequeue means removing the front item. The picture demonstrates the FIFO access.\nThe difference between stacks and queues is in removing. In a stack we remove the item the most recently added; in a queue, we remove the item the least recently added.", 
            "title": "Queues"
        }, 
        {
            "location": "/ds_stack_queue/#implementation_1", 
            "text": "In the standard library of classes, the data type queue is an adapter class, meaning that a queue is built on top of other data structures. The underlying structure for a queue could be an array, a Vector, an ArrayList, a LinkedList, or any other collection. Regardless of the type of the underlying data structure, a queue must implement the same functionality. This is achieved by providing a unique interface.  interface QueueInterface\u2039AnyType \n{\n   public boolean isEmpty();\n\n   public AnyType getFront();\n\n   public AnyType dequeue();\n\n   public void enqueue(AnyType e);\n\n   public void clear();\n}  Each of the above basic operations must run at constant time O(1). The following picture demonstrates the idea of implementation by composition.", 
            "title": "Implementation"
        }, 
        {
            "location": "/ds_stack_queue/#circular-queue", 
            "text": "Given an array A of a default size (\u2265 1) with two references back and front, originally set to -1 and 0 respectively. Each time we insert (enqueue) a new item, we increase the back index; when we remove (dequeue) an item - we increase the front index. Here is a picture that illustrates the model after a few steps:   As you see from the picture, the queue logically moves in the array from left to right. After several moves back reaches the end, leaving no space for adding new elements   However, there is a free space before the front index. We shall use that space for enqueueing new items, i.e. the next entry will be stored at index 0, then 1, until front. Such a model is called a wrap around queue or a circular queue   Finally, when back reaches front, the queue is full. There are two choices to handle a full queue:a) throw an exception; b) double the array size.  The circular queue implementation is done by using the modulo operator (denoted %), which is computed by taking the remainder of division (for example, 8%5 is 3). By using the modulo operator, we can view the queue as a circular array, where the \"wrapped around\" can be simulated as \"back % array_size\". In addition to the back and front indexes, we maintain another index: cur - for counting the number of elements in a queue. Having this index simplifies a logic of implementation.  See ArrayQueue.java for a complete implementation of a circular queue.", 
            "title": "Circular Queue"
        }, 
        {
            "location": "/ds_stack_queue/#applications_1", 
            "text": "The simplest two search techniques are known as Depth-First Search(DFS) and Breadth-First Search (BFS). These two searches are described by looking at how the search tree (representing all the possible paths from the start) will be traversed.", 
            "title": "Applications"
        }, 
        {
            "location": "/ds_stack_queue/#deapth-first-search-with-a-stack", 
            "text": "In depth-first search we go down a path until we get to a dead end; then we backtrack or back up (by popping a stack) to get an alternative path.  Create a stack\nCreate a new choice point\nPush the choice point onto the stack\nwhile (not found and stack is not empty)\n    Pop the stack\n    Find all possible choices after the last one tried\n    Push these choices onto the stack\nReturn", 
            "title": "Deapth-First Search with a Stack"
        }, 
        {
            "location": "/ds_stack_queue/#breadth-first-search-with-a-queue", 
            "text": "In breadth-first search we explore all the nearest possibilities by finding all possible successors and enqueue them to a queue.  Create a queue\nCreate a new choice point\nEnqueue the choice point onto the queue\nwhile (not found and queue is not empty)\n    Dequeue the queue\n    Find all possible choices after the last one tried\n    Enqueue these choices onto the queue\nReturn  We will see more on search techniques later in the course.", 
            "title": "Breadth-First Search with a Queue"
        }, 
        {
            "location": "/ds_stack_queue/#arithmetic-expression-evaluation", 
            "text": "An important application of stacks is in parsing. For example, a compiler must parse arithmetic expressions written using infix notation:  1 + ((2 + 3) * 4 + 5)*6  We break the problem of parsing infix expressions into two stages. First, we convert from infix to a different representation called postfix. Then we parse the postfix expression, which is a somewhat easier problem than directly parsing infix.  Converting from Infix to Postfix.  Typically, we deal with expressions in infix notation  2 + 5  where the operators (e.g. +, *) are written between the operands (e.q, 2 and 5). Writing the operators after the operands gives a postfix expression 2 and 5 are called operands, and the '+' is operator. The above arithmetic expression is called infix, since the operator is in between operands. The expression  2 5 +  Writing the operators before the operands gives a prefix expression  +2 5  Suppose you want to compute the cost of your shopping trip. To do so, you add a list of numbers and multiply them by the local sales tax (7.25%):  70 + 150 * 1.0725  Depending on the calculator, the answer would be either 235.95 or 230.875. To avoid this confusion we shall use a postfix notation  70  150 + 1.0725 *  Postfix has the nice property that parentheses are unnecessary.  Now, we describe how to convert from infix to postfix.   Read in the tokens one at a time  If a token is an integer, write it into the output  If a token is an operator, push it to the stack, if the stack is empty. If the stack is not empty, you pop entries with higher or equal priority and only then you push that 1. token to the stack.  If a token is a left parentheses '(', push it to the stack  If a token is a right parentheses ')', you pop entries until you meet '('.  When you finish reading the string, you pop up all tokens which are left there.  Arithmetic precedence is in increasing order: '+', '-', '*', '/';   Example. Suppose we have an infix expression:2+(4+3*2+1)/3. We read the string by characters.  '2' - send to the output.\n'+' - push on the stack.\n'(' - push on the stack.\n'4' - send to the output.\n'+' - push on the stack.\n'3' - send to the output.\n'*' - push on the stack.\n'2' - send to the output.  Evaluating a Postfix Expression . We describe how to parse and evaluate a postfix expression.   We read the tokens in one at a time.  If it is an integer, push it on the stack  If it is a binary operator, pop the top two elements from the stack, apply the operator, and push the result back on the stack.   Consider the following postfix expression  5 9 3 + 4 2 * * 7 + *  Here is a chain of operations  Stack Operations              Output\n--------------------------------------\npush(5);                        5\npush(9);                        5 9\npush(3);                        5 9 3\npush(pop() + pop())             5 12\npush(4);                        5 12 4\npush(2);                        5 12 4 2\npush(pop() * pop())             5 12 8\npush(pop() * pop())             5 96\npush(7)                         5 96 7\npush(pop() + pop())             5 103\npush(pop() * pop())             515  Note, that division is not a commutative operation, so 2/3 is not the same as 3/2.", 
            "title": "Arithmetic Expression Evaluation"
        }, 
        {
            "location": "/ds_stack_queue/#challenges", 
            "text": "Stacks: Balanced Brackets  Queues: A Tale of Two Stacks", 
            "title": "Challenges"
        }, 
        {
            "location": "/ds_stack_queue/#references", 
            "text": "\"Stacks and Queues\".  Victor S.Adamchik, CMU . 2009", 
            "title": "References"
        }, 
        {
            "location": "/ds_hash_table/", 
            "text": "Hash Table\n\n\nHash Table is a data structure which stores data in an associative manner. In a hash table, data is stored in an array format, where each data value has its own unique index value. Access of data becomes very fast if we know the index of the desired data.\n\n\nThus, it becomes a data structure in which insertion and search operations are very fast irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hash technique to generate an index where an element is to be inserted or is to be located from.\n\n\nHashing\n\n\nHashing is a technique to convert a range of key values into a range of indexes of an array. We're going to use modulo operator to get a range of key values. Consider an example of hash table of size 20, and the following items are to be stored. Item are in the (key,value) format.\n\n\n\n\n\n\n(1,20)\n\n\n(2,70)\n\n\n(42,80)\n\n\n(4,25)\n\n\n(12,44)\n\n\n(14,32)\n\n\n(17,11)\n\n\n(13,78)\n\n\n(37,98)\n\n\n\n\n\n\n\n\n\n\nSr. No.\n\n\nKey\n\n\nHash\n\n\nArray Index\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1 % 20 = 1\n\n\n1\n\n\n\n\n\n\n2\n\n\n2\n\n\n2 % 20 = 2\n\n\n2\n\n\n\n\n\n\n3\n\n\n42\n\n\n42 % 20 = 2\n\n\n2\n\n\n\n\n\n\n4\n\n\n4\n\n\n4 % 20 = 4\n\n\n4\n\n\n\n\n\n\n5\n\n\n12\n\n\n12 % 20 = 12\n\n\n12\n\n\n\n\n\n\n6\n\n\n14\n\n\n4 % 20 = 14\n\n\n14\n\n\n\n\n\n\n7\n\n\n17\n\n\n7 % 20 = 17\n\n\n17\n\n\n\n\n\n\n8\n\n\n13\n\n\n3 % 20 = 13\n\n\n13\n\n\n\n\n\n\n9\n\n\n37\n\n\n7 % 20 = 17\n\n\n17\n\n\n\n\n\n\n\n\nLinear Probing\n\n\nAs we can see, it may happen that the hashing technique is used to create an already used index of the array. In such a case, we can search the next empty location in the array by looking into the next cell until we find an empty cell. This technique is called linear probing.\n\n\n\n\n\n\n\n\nSr. No.\n\n\nKey\n\n\nHash\n\n\nArray Index\n\n\nAfter Linear Probing, Array Index\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1 % 20 = 1\n\n\n1\n\n\n1\n\n\n\n\n\n\n2\n\n\n2\n\n\n2 % 20 = 2\n\n\n2\n\n\n2\n\n\n\n\n\n\n3\n\n\n42\n\n\n42 % 20 = 2\n\n\n2\n\n\n3\n\n\n\n\n\n\n4\n\n\n4\n\n\n4 % 20 = 4\n\n\n4\n\n\n4\n\n\n\n\n\n\n5\n\n\n12\n\n\n12 % 20 = 12\n\n\n12\n\n\n12\n\n\n\n\n\n\n6\n\n\n14\n\n\n14 % 20 = 14\n\n\n14\n\n\n14\n\n\n\n\n\n\n7\n\n\n17\n\n\n17 % 20 = 17\n\n\n17\n\n\n17\n\n\n\n\n\n\n8\n\n\n13\n\n\n13 % 20 = 13\n\n\n13\n\n\n13\n\n\n\n\n\n\n9\n\n\n37\n\n\n37 % 20 = 17\n\n\n17\n\n\n18\n\n\n\n\n\n\n\n\nBasic Operations\n\n\nFollowing are the basic primary operations of a hash table.\n\n\n\n\nSearch\n \u2212 Searches an element in a hash table.\n\n\nInsert\n \u2212 inserts an element in a hash table.\n\n\ndelete\n \u2212 Deletes an element from a hash table.\n\n\n\n\nDataItem\n\n\nDefine a data item having some data and key, based on which the search is to be conducted in a hash table.\n\n\nstruct DataItem {\n   int data;   \n   int key;\n};\n\n\n\n\nHash Method\n\n\nDefine a hashing method to compute the hash code of the key of the data item.\n\n\nint hashCode(int key){\n   return key % SIZE;\n}\n\n\n\n\nSearch Operation\n\n\nWhenever an element is to be searched, compute the hash code of the key passed and locate the element using that hash code as index in the array. Use linear probing to get the element ahead if the element is not found at the computed hash code.\n\n\nExample\n\n\nstruct DataItem *search(int key) {\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty \n   while(hashArray[hashIndex] != NULL) {\n\n      if(hashArray[hashIndex]-\nkey == key)\n         return hashArray[hashIndex];\n\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }\n\n   return NULL;        \n}\n\n\n\n\nInsert Operation\n\n\nWhenever an element is to be inserted, compute the hash code of the key passed and locate the index using that hash code as an index in the array. Use linear probing for empty location, if an element is found at the computed hash code.\n\n\nExample\n\n\nvoid insert(int key,int data) {\n   struct DataItem *item = (struct DataItem*) malloc(sizeof(struct DataItem));\n   item-\ndata = data;  \n   item-\nkey = key;     \n\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty or deleted cell\n   while(hashArray[hashIndex] != NULL \n hashArray[hashIndex]-\nkey != -1) {\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }\n\n   hashArray[hashIndex] = item;        \n}\n\n\n\n\nDelete Operation\n\n\nWhenever an element is to be deleted, compute the hash code of the key passed and locate the index using that hash code as an index in the array. Use linear probing to get the element ahead if an element is not found at the computed hash code. When found, store a dummy item there to keep the performance of the hash table intact.\n\n\nExample\n\n\nstruct DataItem* delete(struct DataItem* item) {\n   int key = item-\nkey;\n\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty \n   while(hashArray[hashIndex] !=NULL) {\n\n      if(hashArray[hashIndex]-\nkey == key) {\n         struct DataItem* temp = hashArray[hashIndex]; \n\n         //assign a dummy item at deleted position\n         hashArray[hashIndex] = dummyItem; \n         return temp;\n      } \n\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }  \n\n   return NULL;        \n}", 
            "title": "Hash Tables"
        }, 
        {
            "location": "/ds_hash_table/#hash-table", 
            "text": "Hash Table is a data structure which stores data in an associative manner. In a hash table, data is stored in an array format, where each data value has its own unique index value. Access of data becomes very fast if we know the index of the desired data.  Thus, it becomes a data structure in which insertion and search operations are very fast irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hash technique to generate an index where an element is to be inserted or is to be located from.", 
            "title": "Hash Table"
        }, 
        {
            "location": "/ds_hash_table/#hashing", 
            "text": "Hashing is a technique to convert a range of key values into a range of indexes of an array. We're going to use modulo operator to get a range of key values. Consider an example of hash table of size 20, and the following items are to be stored. Item are in the (key,value) format.    (1,20)  (2,70)  (42,80)  (4,25)  (12,44)  (14,32)  (17,11)  (13,78)  (37,98)      Sr. No.  Key  Hash  Array Index      1  1  1 % 20 = 1  1    2  2  2 % 20 = 2  2    3  42  42 % 20 = 2  2    4  4  4 % 20 = 4  4    5  12  12 % 20 = 12  12    6  14  4 % 20 = 14  14    7  17  7 % 20 = 17  17    8  13  3 % 20 = 13  13    9  37  7 % 20 = 17  17", 
            "title": "Hashing"
        }, 
        {
            "location": "/ds_hash_table/#linear-probing", 
            "text": "As we can see, it may happen that the hashing technique is used to create an already used index of the array. In such a case, we can search the next empty location in the array by looking into the next cell until we find an empty cell. This technique is called linear probing.     Sr. No.  Key  Hash  Array Index  After Linear Probing, Array Index      1  1  1 % 20 = 1  1  1    2  2  2 % 20 = 2  2  2    3  42  42 % 20 = 2  2  3    4  4  4 % 20 = 4  4  4    5  12  12 % 20 = 12  12  12    6  14  14 % 20 = 14  14  14    7  17  17 % 20 = 17  17  17    8  13  13 % 20 = 13  13  13    9  37  37 % 20 = 17  17  18", 
            "title": "Linear Probing"
        }, 
        {
            "location": "/ds_hash_table/#basic-operations", 
            "text": "Following are the basic primary operations of a hash table.   Search  \u2212 Searches an element in a hash table.  Insert  \u2212 inserts an element in a hash table.  delete  \u2212 Deletes an element from a hash table.", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/ds_hash_table/#dataitem", 
            "text": "Define a data item having some data and key, based on which the search is to be conducted in a hash table.  struct DataItem {\n   int data;   \n   int key;\n};", 
            "title": "DataItem"
        }, 
        {
            "location": "/ds_hash_table/#hash-method", 
            "text": "Define a hashing method to compute the hash code of the key of the data item.  int hashCode(int key){\n   return key % SIZE;\n}", 
            "title": "Hash Method"
        }, 
        {
            "location": "/ds_hash_table/#search-operation", 
            "text": "Whenever an element is to be searched, compute the hash code of the key passed and locate the element using that hash code as index in the array. Use linear probing to get the element ahead if the element is not found at the computed hash code.  Example  struct DataItem *search(int key) {\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty \n   while(hashArray[hashIndex] != NULL) {\n\n      if(hashArray[hashIndex]- key == key)\n         return hashArray[hashIndex];\n\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }\n\n   return NULL;        \n}", 
            "title": "Search Operation"
        }, 
        {
            "location": "/ds_hash_table/#insert-operation", 
            "text": "Whenever an element is to be inserted, compute the hash code of the key passed and locate the index using that hash code as an index in the array. Use linear probing for empty location, if an element is found at the computed hash code.  Example  void insert(int key,int data) {\n   struct DataItem *item = (struct DataItem*) malloc(sizeof(struct DataItem));\n   item- data = data;  \n   item- key = key;     \n\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty or deleted cell\n   while(hashArray[hashIndex] != NULL   hashArray[hashIndex]- key != -1) {\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }\n\n   hashArray[hashIndex] = item;        \n}", 
            "title": "Insert Operation"
        }, 
        {
            "location": "/ds_hash_table/#delete-operation", 
            "text": "Whenever an element is to be deleted, compute the hash code of the key passed and locate the index using that hash code as an index in the array. Use linear probing to get the element ahead if an element is not found at the computed hash code. When found, store a dummy item there to keep the performance of the hash table intact.  Example  struct DataItem* delete(struct DataItem* item) {\n   int key = item- key;\n\n   //get the hash \n   int hashIndex = hashCode(key);\n\n   //move in array until an empty \n   while(hashArray[hashIndex] !=NULL) {\n\n      if(hashArray[hashIndex]- key == key) {\n         struct DataItem* temp = hashArray[hashIndex]; \n\n         //assign a dummy item at deleted position\n         hashArray[hashIndex] = dummyItem; \n         return temp;\n      } \n\n      //go to next cell\n      ++hashIndex;\n\n      //wrap around the table\n      hashIndex %= SIZE;\n   }  \n\n   return NULL;        \n}", 
            "title": "Delete Operation"
        }, 
        {
            "location": "/ds_tree/", 
            "text": "Tree\n\n\nBinary Tree\n\n\nFundamentally, a binary tree is composed of nodes connected by edges (with further restrictions discussed below). Some binary tree, \nt\n, is either empty or consists of a single root element with two distinct binary tree child elements known as the \nleft subtree\n and the \nright subtree\n of \nt\n. As the name \nbinary\n suggests, a node in a binary tree has a \nmaximum\n of \n2\n children.\n\n\nThe following diagrams depict two different binary trees: \n\n\n \n\n\nHere are the basic facts and terms to know about binary trees:\n\n\n\n\nThe convention for binary tree diagrams is that the \nroot\n is at the top, and the subtrees branch down from it.\n\n\nA node's \nleft\n and \nright\n subtrees are referred to as \nchildren\n, and that node can be referred to as the \nparent\n of those subtrees.\n\n\nA non-root node with no children is called a \nleaf\n.\n\n\nSome node \na\n is an ancestor of some node \nb\n if \nb\n is located in a left or right subtree whose root node is \na\n. This means that the root node of binary tree \nt\n is the ancestor of all other nodes in the tree.\n\n\nIf some node \na\n is an ancestor of some node \nb\n, then the path from \na\n to \nb\n is the sequence of nodes starting with \na\n, moving down the ancestral chain of children, and ending with bb.\n\n\nThe depth (or level) of some node \na\n is its distance (i.e., number of edges) from the tree's root node.\n\n\nSimply put, the height of a tree is the number of edges between the root node and its furthest leaf.\n\n\nMore technically put, it's \n1+max(height(leftSubtree), height(rightSubtree))\n ) (i.e., one more than the maximum of the heights of its left and right subtrees).\n\n\nAny node has a height of \n1\n, and the height of an empty subtree is \n - 1 \n.\n\n\nBecause the height of each node is \n1 + \n the maximum height of its subtrees and an empty subtree's height is \n - 1 \n, the height of a single-element tree or leaf node is \n0\n.\n\n\n\n\n\n\n\n\nLet's apply some of the terms we learned above to the binary tree on the right:\n\n\n\n\n\n\nThe root node is \nA\n.\n\n\n\n\n\n\nThe respective left and right children of \nA\n are \nB\n and \nE\n. The left child of \nB\n is \nC\n. The respective left and right children of \nE\n are \nF\n and \nD\n.\n\n\n\n\n\n\nNodes \nC\n, \nF\n, and \nD\n are leaves (i.e., each node is a leaf).\n\n\n\n\n\n\nThe root is the ancestor of all other nodes, \nB\n is an ancestor of \nC\n, and \nE\n is an ancestor of \nF\n and \nD\n.\n\n\n\n\n\n\nThe path between \nA\n and \nC\n is \n A \\rightarrow B \\rightarrow C \n. The path between \nA\n and \nF\n is \n A \\rightarrow E \\rightarrow F \n. The path between \nA\n and \nD\n is A \n \\rightarrow E \\rightarrow D \n.\n\n\n\n\n\n\nThe depth of root node \nA\n is \n0\n. The depth of nodes \nB\n and \nE\n is \n1\n. The depth of nodes \nC\n, \nF\n, and \nD\n, is \n2\n.\n\n\n\n\n\n\nThe height of the tree, \n height(t) \n, is \n2\n. We calculate this recursively as \n height(t)=1+(max(height(root.leftChild),height(root.rightChild))) \n.\n\n\n\n\n\n\nBecause this is long and complicated when expanded, we'll break it down using an image of a slightly simpler version of \nt\n whose height is still \n2\n: \n\n\n \n\n\nBinary Search Tree\n\n\nA Binary Search Tree (BST), \nt\n, is a binary tree that is either empty or satisfies the following three conditions:\n\n\n\n\n\n\nEach element in the left subtree of \nt\n is less than or equal to the root element of \nt\n (i.e., \n max(leftTree(t).value) \\leq t.valuemax(leftTree(t).value) \\leq t.value \n).\n\n\n\n\n\n\nEach element in the right subtree of \nt\n is greater than the root element of \nt\n (i.e., \n max(rightTree(t).value) \\ge t.valuemax(rightTree(t).value) \\ge t.value\n).\n\n\n\n\n\n\nBoth \n leftTree(t) \n and \n rightTree(t) \n are BSTs.\n\n\n\n\n\n\nYou can essentially think of it as a regular binary tree where for each node parent having a \n leftChild \n and \n rightChild \n, \n leftChild.value \\leq parent.value \\le rightChild.value \n. In the first diagram at the top of this article, the binary tree of integers on the left side is a binary search tree.\n\n\nAdvantages and Drawbacks\n\n\n\n\nSearching for elements is very fast.\n\n\n\n\nWe know that each node has a maximum of two children and we know that the \n \\leq \n items are always in the left subtree and the \n > \n items are always in the right subtree. To search for an element, we simply need to compare the value we want against the value stored in the root node of the current subtree and work our way down the appropriate child subtrees until we either find the value we're looking for or we hit \nnull\n (i.e., an empty subtree) which indicates the item is not in the BST. Inserting or searching for a node in a balanced tree is \n O(\\log n) \n because you're discarding half of the possible values each time you go left or right.\n\n\n\n\nIt can easily become unbalanced.\n\n\n\n\nDepending on the insertion order, the tree can very easily become unbalanced (which makes for longer search times). For example, if we create a new tree where the sequence of inserted nodes is \n 2 \\rightarrow 1 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow 6 \n, we end up with the following unbalanced tree: \n\n\n\n\nObserve that the root's left subtree only has one node, whereas the root's right subtree has four nodes. For this reason, inserting or searching for a node in an unbalanced tree is \n O(n) \n.\n\n\nChallenges\n\n\n\n\n\"Trees: Is This a Binary Search Tree?\". \nhackerrank\n. 2016\n\n\n\n\nReferences\n\n\n\n\n\"Binary Trees and Binary Search Trees\". \nAllisonP, hackerrank\n. 2016", 
            "title": "Trees"
        }, 
        {
            "location": "/ds_tree/#tree", 
            "text": "", 
            "title": "Tree"
        }, 
        {
            "location": "/ds_tree/#binary-tree", 
            "text": "Fundamentally, a binary tree is composed of nodes connected by edges (with further restrictions discussed below). Some binary tree,  t , is either empty or consists of a single root element with two distinct binary tree child elements known as the  left subtree  and the  right subtree  of  t . As the name  binary  suggests, a node in a binary tree has a  maximum  of  2  children.  The following diagrams depict two different binary trees:      Here are the basic facts and terms to know about binary trees:   The convention for binary tree diagrams is that the  root  is at the top, and the subtrees branch down from it.  A node's  left  and  right  subtrees are referred to as  children , and that node can be referred to as the  parent  of those subtrees.  A non-root node with no children is called a  leaf .  Some node  a  is an ancestor of some node  b  if  b  is located in a left or right subtree whose root node is  a . This means that the root node of binary tree  t  is the ancestor of all other nodes in the tree.  If some node  a  is an ancestor of some node  b , then the path from  a  to  b  is the sequence of nodes starting with  a , moving down the ancestral chain of children, and ending with bb.  The depth (or level) of some node  a  is its distance (i.e., number of edges) from the tree's root node.  Simply put, the height of a tree is the number of edges between the root node and its furthest leaf.  More technically put, it's  1+max(height(leftSubtree), height(rightSubtree))  ) (i.e., one more than the maximum of the heights of its left and right subtrees).  Any node has a height of  1 , and the height of an empty subtree is   - 1  .  Because the height of each node is  1 +   the maximum height of its subtrees and an empty subtree's height is   - 1  , the height of a single-element tree or leaf node is  0 .     Let's apply some of the terms we learned above to the binary tree on the right:    The root node is  A .    The respective left and right children of  A  are  B  and  E . The left child of  B  is  C . The respective left and right children of  E  are  F  and  D .    Nodes  C ,  F , and  D  are leaves (i.e., each node is a leaf).    The root is the ancestor of all other nodes,  B  is an ancestor of  C , and  E  is an ancestor of  F  and  D .    The path between  A  and  C  is   A \\rightarrow B \\rightarrow C  . The path between  A  and  F  is   A \\rightarrow E \\rightarrow F  . The path between  A  and  D  is A   \\rightarrow E \\rightarrow D  .    The depth of root node  A  is  0 . The depth of nodes  B  and  E  is  1 . The depth of nodes  C ,  F , and  D , is  2 .    The height of the tree,   height(t)  , is  2 . We calculate this recursively as   height(t)=1+(max(height(root.leftChild),height(root.rightChild)))  .    Because this is long and complicated when expanded, we'll break it down using an image of a slightly simpler version of  t  whose height is still  2 :", 
            "title": "Binary Tree"
        }, 
        {
            "location": "/ds_tree/#binary-search-tree", 
            "text": "A Binary Search Tree (BST),  t , is a binary tree that is either empty or satisfies the following three conditions:    Each element in the left subtree of  t  is less than or equal to the root element of  t  (i.e.,   max(leftTree(t).value) \\leq t.valuemax(leftTree(t).value) \\leq t.value  ).    Each element in the right subtree of  t  is greater than the root element of  t  (i.e.,   max(rightTree(t).value) \\ge t.valuemax(rightTree(t).value) \\ge t.value ).    Both   leftTree(t)   and   rightTree(t)   are BSTs.    You can essentially think of it as a regular binary tree where for each node parent having a   leftChild   and   rightChild  ,   leftChild.value \\leq parent.value \\le rightChild.value  . In the first diagram at the top of this article, the binary tree of integers on the left side is a binary search tree.", 
            "title": "Binary Search Tree"
        }, 
        {
            "location": "/ds_tree/#advantages-and-drawbacks", 
            "text": "Searching for elements is very fast.   We know that each node has a maximum of two children and we know that the   \\leq   items are always in the left subtree and the   >   items are always in the right subtree. To search for an element, we simply need to compare the value we want against the value stored in the root node of the current subtree and work our way down the appropriate child subtrees until we either find the value we're looking for or we hit  null  (i.e., an empty subtree) which indicates the item is not in the BST. Inserting or searching for a node in a balanced tree is   O(\\log n)   because you're discarding half of the possible values each time you go left or right.   It can easily become unbalanced.   Depending on the insertion order, the tree can very easily become unbalanced (which makes for longer search times). For example, if we create a new tree where the sequence of inserted nodes is   2 \\rightarrow 1 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow 6  , we end up with the following unbalanced tree:    Observe that the root's left subtree only has one node, whereas the root's right subtree has four nodes. For this reason, inserting or searching for a node in an unbalanced tree is   O(n)  .", 
            "title": "Advantages and Drawbacks"
        }, 
        {
            "location": "/ds_tree/#challenges", 
            "text": "\"Trees: Is This a Binary Search Tree?\".  hackerrank . 2016", 
            "title": "Challenges"
        }, 
        {
            "location": "/ds_tree/#references", 
            "text": "\"Binary Trees and Binary Search Trees\".  AllisonP, hackerrank . 2016", 
            "title": "References"
        }, 
        {
            "location": "/ds_binary_search_tree/", 
            "text": "Binary Search Tree\n\n\nA Binary Search Tree (BST) is a tree in which all the nodes follow the below-mentioned properties\n\n\n\n\nThe left sub-tree of a node has a key less than or equal to its parent node's key.\n\n\nThe right sub-tree of a node has a key greater than to its parent node's key.\n\n\n\n\nThus, BST divides all its sub-trees into two segments; the left sub-tree and the right sub-tree and can be defined as\n\n\nleft_subtree (keys)  \u2264  node (key)  \u2264  right_subtree (keys)\n\n\n\n\nRepresentation\n\n\nBST is a collection of nodes arranged in a way where they maintain BST properties. Each node has a key and an associated value. While searching, the desired key is compared to the keys in BST and if found, the associated value is retrieved.\n\n\nFollowing is a pictorial representation of BST \n\n\n\n\nWe observe that the root node key (27) has all less-valued keys on the left sub-tree and the higher valued keys on the right sub-tree.\n\n\nBasic Operations\n\n\nFollowing are the basic operations of a tree\n\n\n\n\nSearch\n \u2212 Searches an element in a tree.\n\n\nInsert\n \u2212 Inserts an element in a tree.\n\n\nPre-order Traversal\n \u2212 Traverses a tree in a pre-order manner.\n\n\nIn-order Traversal\n \u2212 Traverses a tree in an in-order manner.\n\n\nPost-order Traversal\n \u2212 Traverses a tree in a post-order manner.\n\n\n\n\nNode\n\n\nDefine a node having some data, references to its left and right child nodes.\n\n\nstruct node {\n   int data;   \n   struct node *leftChild;\n   struct node *rightChild;\n};\n\n\n\n\nSearch Operation\n\n\nWhenever an element is to be searched, start searching from the root node. Then if the data is less than the key value, search for the element in the left subtree. Otherwise, search for the element in the right subtree. Follow the same algorithm for each node.\n\n\nAlgorithm\n\n\nstruct node* search(int data){\n   struct node *current = root;\n   printf(\nVisiting elements: \n);\n\n   while(current-\ndata != data){\n\n      if(current != NULL) {\n         printf(\n%d \n,current-\ndata);\n\n         //go to left tree\n         if(current-\ndata \n data){\n            current = current-\nleftChild;\n         }//else go to right tree\n         else {                \n            current = current-\nrightChild;\n         }\n\n         //not found\n         if(current == NULL){\n            return NULL;\n         }\n      }         \n   }\n   return current;\n}\n\n\n\n\nInsert Operation\n\n\nWhenever an element is to be inserted, first locate its proper location. Start searching from the root node, then if the data is less than the key value, search for the empty location in the left subtree and insert the data. Otherwise, search for the empty location in the right subtree and insert the data.\n\n\nAlgorithm\n\n\nvoid insert(int data) {\n   struct node *tempNode = (struct node*) malloc(sizeof(struct node));\n   struct node *current;\n   struct node *parent;\n\n   tempNode-\ndata = data;\n   tempNode-\nleftChild = NULL;\n   tempNode-\nrightChild = NULL;\n\n   //if tree is empty\n   if(root == NULL) {\n      root = tempNode;\n   } else {\n      current = root;\n      parent = NULL;\n\n      while(1) {                \n         parent = current;\n\n         //go to left of the tree\n         if(data \n parent-\ndata) {\n            current = current-\nleftChild;                \n            //insert to the left\n\n            if(current == NULL) {\n               parent-\nleftChild = tempNode;\n               return;\n            }\n         }//go to right of the tree\n         else {\n            current = current-\nrightChild;\n\n            //insert to the right\n            if(current == NULL) {\n               parent-\nrightChild = tempNode;\n               return;\n            }\n         }\n      }            \n   }\n}", 
            "title": "Binary Search Trees"
        }, 
        {
            "location": "/ds_binary_search_tree/#binary-search-tree", 
            "text": "A Binary Search Tree (BST) is a tree in which all the nodes follow the below-mentioned properties   The left sub-tree of a node has a key less than or equal to its parent node's key.  The right sub-tree of a node has a key greater than to its parent node's key.   Thus, BST divides all its sub-trees into two segments; the left sub-tree and the right sub-tree and can be defined as  left_subtree (keys)  \u2264  node (key)  \u2264  right_subtree (keys)", 
            "title": "Binary Search Tree"
        }, 
        {
            "location": "/ds_binary_search_tree/#representation", 
            "text": "BST is a collection of nodes arranged in a way where they maintain BST properties. Each node has a key and an associated value. While searching, the desired key is compared to the keys in BST and if found, the associated value is retrieved.  Following is a pictorial representation of BST    We observe that the root node key (27) has all less-valued keys on the left sub-tree and the higher valued keys on the right sub-tree.", 
            "title": "Representation"
        }, 
        {
            "location": "/ds_binary_search_tree/#basic-operations", 
            "text": "Following are the basic operations of a tree   Search  \u2212 Searches an element in a tree.  Insert  \u2212 Inserts an element in a tree.  Pre-order Traversal  \u2212 Traverses a tree in a pre-order manner.  In-order Traversal  \u2212 Traverses a tree in an in-order manner.  Post-order Traversal  \u2212 Traverses a tree in a post-order manner.", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/ds_binary_search_tree/#node", 
            "text": "Define a node having some data, references to its left and right child nodes.  struct node {\n   int data;   \n   struct node *leftChild;\n   struct node *rightChild;\n};", 
            "title": "Node"
        }, 
        {
            "location": "/ds_binary_search_tree/#search-operation", 
            "text": "Whenever an element is to be searched, start searching from the root node. Then if the data is less than the key value, search for the element in the left subtree. Otherwise, search for the element in the right subtree. Follow the same algorithm for each node.  Algorithm  struct node* search(int data){\n   struct node *current = root;\n   printf( Visiting elements:  );\n\n   while(current- data != data){\n\n      if(current != NULL) {\n         printf( %d  ,current- data);\n\n         //go to left tree\n         if(current- data   data){\n            current = current- leftChild;\n         }//else go to right tree\n         else {                \n            current = current- rightChild;\n         }\n\n         //not found\n         if(current == NULL){\n            return NULL;\n         }\n      }         \n   }\n   return current;\n}", 
            "title": "Search Operation"
        }, 
        {
            "location": "/ds_binary_search_tree/#insert-operation", 
            "text": "Whenever an element is to be inserted, first locate its proper location. Start searching from the root node, then if the data is less than the key value, search for the empty location in the left subtree and insert the data. Otherwise, search for the empty location in the right subtree and insert the data.  Algorithm  void insert(int data) {\n   struct node *tempNode = (struct node*) malloc(sizeof(struct node));\n   struct node *current;\n   struct node *parent;\n\n   tempNode- data = data;\n   tempNode- leftChild = NULL;\n   tempNode- rightChild = NULL;\n\n   //if tree is empty\n   if(root == NULL) {\n      root = tempNode;\n   } else {\n      current = root;\n      parent = NULL;\n\n      while(1) {                \n         parent = current;\n\n         //go to left of the tree\n         if(data   parent- data) {\n            current = current- leftChild;                \n            //insert to the left\n\n            if(current == NULL) {\n               parent- leftChild = tempNode;\n               return;\n            }\n         }//go to right of the tree\n         else {\n            current = current- rightChild;\n\n            //insert to the right\n            if(current == NULL) {\n               parent- rightChild = tempNode;\n               return;\n            }\n         }\n      }            \n   }\n}", 
            "title": "Insert Operation"
        }, 
        {
            "location": "/ds_heap/", 
            "text": "Heaps\n\n\nA heap is just what it sounds like \u2014  a pile of values organized into a binary tree-like structure adhering to some ordering property. When we add elements to a heap, we fill this tree-like structure from left to right, level by level. This makes heaps really easy to implement in an array, where the value for some index ii's left child is located at index \n 2i+1 \n and the value for its right child is at index \n 2i+2 \n (using zero-indexing). Here are the two most fundamental heap operations:\n\n\n\n\nadd\n: Insert an element into the heap. You may also see this referred to as push.\n\n\npoll\n: Retrieve and remove the root element of the heap. You may also see this referred to as pop.\n\n\n\n\nMax Heap\n\n\nThis type heap orders the maximum value at the root.\n\n\nWhen we \nadd\n the values \n 1\u21922\u21923\u21924 \n to a Max heap, it looks like this:\n\n\n\n\nWhen we \npoll\n the same Max heap until it's empty, it looks like this:\n\n\n\n\nMin Heap\n\n\nThis type of heap orders the minimum value at the root.\n\n\nWhen we \nadd\n the values \n 1\u21922\u21923\u21924 \n to a Min heap, it looks like this:\n\n\n \n\n\nWhen we \npoll\n the same Min heap until it's empty, it looks like this:\n\n\n \n\n\nApplications\n\n\nThe heap data structure has many applications.\n\n\n\n\nHeapsort\n: One of the best sorting methods being in-place and with no quadratic worst-case scenarios.\n\n\nSelection algorithms\n: A heap allows access to the min or max element in constant time, and other selections (such as median or kth-element) can be done in sub-linear time on data that is in a heap.\n\n\nGraph algorithms\n: By using heaps as internal traversal data structures, run time will be reduced by polynomial order. Examples of such problems are Prim's minimal-spanning-tree algorithm and Dijkstra's shortest-path algorithm.\n\n\nPriority Queue\n: A priority queue is an abstract concept like \"a list\" or \"a map\"; just as a list can be implemented with a linked list or an array, a priority queue can be implemented with a heap or a variety of other methods.\n\n\nOrder statistics\n: The Heap data structure can be used to efficiently find the kth smallest (or largest) element in an array.\n\n\n\n\nChallenges\n\n\n\n\n\"Heaps: Find the Running Median\". \nhackerrank\n. 2016\n\n\n\n\nReferences\n\n\n\n\n\"Heaps\". \nAllisonP, hackerrank\n. 2016\n\n\n\"Heap (data structure)\". \nwikipedia\n. 2016", 
            "title": "Heaps"
        }, 
        {
            "location": "/ds_heap/#heaps", 
            "text": "A heap is just what it sounds like \u2014  a pile of values organized into a binary tree-like structure adhering to some ordering property. When we add elements to a heap, we fill this tree-like structure from left to right, level by level. This makes heaps really easy to implement in an array, where the value for some index ii's left child is located at index   2i+1   and the value for its right child is at index   2i+2   (using zero-indexing). Here are the two most fundamental heap operations:   add : Insert an element into the heap. You may also see this referred to as push.  poll : Retrieve and remove the root element of the heap. You may also see this referred to as pop.", 
            "title": "Heaps"
        }, 
        {
            "location": "/ds_heap/#max-heap", 
            "text": "This type heap orders the maximum value at the root.  When we  add  the values   1\u21922\u21923\u21924   to a Max heap, it looks like this:   When we  poll  the same Max heap until it's empty, it looks like this:", 
            "title": "Max Heap"
        }, 
        {
            "location": "/ds_heap/#min-heap", 
            "text": "This type of heap orders the minimum value at the root.  When we  add  the values   1\u21922\u21923\u21924   to a Min heap, it looks like this:     When we  poll  the same Min heap until it's empty, it looks like this:", 
            "title": "Min Heap"
        }, 
        {
            "location": "/ds_heap/#applications", 
            "text": "The heap data structure has many applications.   Heapsort : One of the best sorting methods being in-place and with no quadratic worst-case scenarios.  Selection algorithms : A heap allows access to the min or max element in constant time, and other selections (such as median or kth-element) can be done in sub-linear time on data that is in a heap.  Graph algorithms : By using heaps as internal traversal data structures, run time will be reduced by polynomial order. Examples of such problems are Prim's minimal-spanning-tree algorithm and Dijkstra's shortest-path algorithm.  Priority Queue : A priority queue is an abstract concept like \"a list\" or \"a map\"; just as a list can be implemented with a linked list or an array, a priority queue can be implemented with a heap or a variety of other methods.  Order statistics : The Heap data structure can be used to efficiently find the kth smallest (or largest) element in an array.", 
            "title": "Applications"
        }, 
        {
            "location": "/ds_heap/#challenges", 
            "text": "\"Heaps: Find the Running Median\".  hackerrank . 2016", 
            "title": "Challenges"
        }, 
        {
            "location": "/ds_heap/#references", 
            "text": "\"Heaps\".  AllisonP, hackerrank . 2016  \"Heap (data structure)\".  wikipedia . 2016", 
            "title": "References"
        }, 
        {
            "location": "/graph_data_structure/", 
            "text": "Graph Data Structure\n\n\nA graph is a pictorial representation of a set of objects where some pairs of objects are connected by links. The interconnected objects are represented by points termed as vertices, and the links that connect the vertices are called edges.\n\n\nFormally, a graph is a pair of sets \n(V, E)\n, where \nV\n is the set of vertices and \nE\n is the set of edges, connecting the pairs of vertices. Take a look at the following graph\n\n\n\n\nIn the above graph,\n\n\n\n\n\n\n\n\nV = {a, b, c, d, e}\n\n\n\n\n\n\n\n\n\n\nE = {ab, ac, bd, cd, de}\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMathematical graphs can be represented in data structure. We can represent a graph using an array of vertices and a two-dimensional array of edges. Before we proceed further, let's familiarize ourselves with some important terms\n\n\n\n\nVertex\n \u2212 Each node of the graph is represented as a vertex. In the following example, the labeled circle represents vertices. Thus, A to G are vertices. We can represent them using an array as shown in the following image. Here A can be identified by index 0. B can be identified using index 1 and so on.\n\n\nEdge\n \u2212 Edge represents a path between two vertices or a line between two vertices. In the following example, the lines from A to B, B to C, and so on represents edges. We can use a two-dimensional array to represent an array as shown in the following image. Here AB can be represented as 1 at row 0, column 1, BC as 1 at row 1, column 2 and so on, keeping other combinations as 0.\n\n\nAdjacency\n \u2212 Two node or vertices are adjacent if they are connected to each other through an edge. In the following example, B is adjacent to A, C is adjacent to B, and so on.\n\n\nPath\n \u2212 Path represents a sequence of edges between the two vertices. In the following example, ABCD represents a path from A to D.\n\n\n\n\n\n\nBasic Operations\n\n\nFollowing are basic primary operations of a Graph \u2212\n\n\n\n\nAdd Vertex\n \u2212 Adds a vertex to the graph.\n\n\nAdd Edge\n \u2212 Adds an edge between the two vertices of the graph.\n\n\nDisplay Vertex\n \u2212 Displays a vertex of the graph.", 
            "title": "Graph Data Structure"
        }, 
        {
            "location": "/graph_data_structure/#graph-data-structure", 
            "text": "A graph is a pictorial representation of a set of objects where some pairs of objects are connected by links. The interconnected objects are represented by points termed as vertices, and the links that connect the vertices are called edges.  Formally, a graph is a pair of sets  (V, E) , where  V  is the set of vertices and  E  is the set of edges, connecting the pairs of vertices. Take a look at the following graph   In the above graph,     V = {a, b, c, d, e}      E = {ab, ac, bd, cd, de}", 
            "title": "Graph Data Structure"
        }, 
        {
            "location": "/graph_data_structure/#definitions", 
            "text": "Mathematical graphs can be represented in data structure. We can represent a graph using an array of vertices and a two-dimensional array of edges. Before we proceed further, let's familiarize ourselves with some important terms   Vertex  \u2212 Each node of the graph is represented as a vertex. In the following example, the labeled circle represents vertices. Thus, A to G are vertices. We can represent them using an array as shown in the following image. Here A can be identified by index 0. B can be identified using index 1 and so on.  Edge  \u2212 Edge represents a path between two vertices or a line between two vertices. In the following example, the lines from A to B, B to C, and so on represents edges. We can use a two-dimensional array to represent an array as shown in the following image. Here AB can be represented as 1 at row 0, column 1, BC as 1 at row 1, column 2 and so on, keeping other combinations as 0.  Adjacency  \u2212 Two node or vertices are adjacent if they are connected to each other through an edge. In the following example, B is adjacent to A, C is adjacent to B, and so on.  Path  \u2212 Path represents a sequence of edges between the two vertices. In the following example, ABCD represents a path from A to D.", 
            "title": "Definitions"
        }, 
        {
            "location": "/graph_data_structure/#basic-operations", 
            "text": "Following are basic primary operations of a Graph \u2212   Add Vertex  \u2212 Adds a vertex to the graph.  Add Edge  \u2212 Adds an edge between the two vertices of the graph.  Display Vertex  \u2212 Displays a vertex of the graph.", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/graph_dfs/", 
            "text": "Depth First Traversal\n\n\nDepth First Search (DFS) algorithm traverses a graph in a depthward motion and uses a stack to remember to get the next vertex to start a search, when a dead end occurs in any iteration.\n\n\n\n\nAs in the example given above, DFS algorithm traverses from A to B to C to D first then to E, then to F and lastly to G. It employs the following rules.\n\n\n\n\nRule 1\n \u2212 Visit the adjacent unvisited vertex. Mark it as visited. Display it. Push it in a stack.\n\n\nRule 2\n \u2212 If no adjacent vertex is found, pop up a vertex from the stack. (It will pop up all the vertices from the stack, which do not have adjacent vertices.)\n\n\nRule 3\n \u2212 Repeat Rule 1 and Rule 2 until the stack is empty.\n\n\n\n\nAlgorithms\n\n\n\n\n\n\n\n\nStep\n\n\nTraversal\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n1.\n\n\n\n\nInitialize the stack.\n\n\n\n\n\n\n2.\n\n\n\n\nMark S as visited and put it onto the stack. Explore any unvisited adjacent node from S. We have three nodes and we can pick any of them. For this example, we shall take the node in an alphabetical order.\n\n\n\n\n\n\n3.\n\n\n\n\nMark A as visited and put it onto the stack. Explore any unvisited adjacent node from A. Both Sand D are adjacent to A but we are concerned for unvisited nodes only.\n\n\n\n\n\n\n4.\n\n\n\n\nVisit D and mark it as visited and put onto the stack. Here, we have B and C nodes, which are adjacent to D and both are unvisited. However, we shall again choose in an alphabetical order.\n\n\n\n\n\n\n5.\n\n\n\n\nWe choose B, mark it as visited and put onto the stack. Here Bdoes not have any unvisited adjacent node. So, we pop Bfrom the stack.\n\n\n\n\n\n\n6.\n\n\n\n\nWe check the stack top for return to the previous node and check if it has any unvisited nodes. Here, we find D to be on the top of the stack.\n\n\n\n\n\n\n7.\n\n\n\n\nOnly unvisited adjacent node is from D is C now. So we visit C, mark it as visited and put it onto the stack.", 
            "title": "DFS: Depth First Traversal"
        }, 
        {
            "location": "/graph_dfs/#depth-first-traversal", 
            "text": "Depth First Search (DFS) algorithm traverses a graph in a depthward motion and uses a stack to remember to get the next vertex to start a search, when a dead end occurs in any iteration.   As in the example given above, DFS algorithm traverses from A to B to C to D first then to E, then to F and lastly to G. It employs the following rules.   Rule 1  \u2212 Visit the adjacent unvisited vertex. Mark it as visited. Display it. Push it in a stack.  Rule 2  \u2212 If no adjacent vertex is found, pop up a vertex from the stack. (It will pop up all the vertices from the stack, which do not have adjacent vertices.)  Rule 3  \u2212 Repeat Rule 1 and Rule 2 until the stack is empty.", 
            "title": "Depth First Traversal"
        }, 
        {
            "location": "/graph_dfs/#algorithms", 
            "text": "Step  Traversal  Description      1.   Initialize the stack.    2.   Mark S as visited and put it onto the stack. Explore any unvisited adjacent node from S. We have three nodes and we can pick any of them. For this example, we shall take the node in an alphabetical order.    3.   Mark A as visited and put it onto the stack. Explore any unvisited adjacent node from A. Both Sand D are adjacent to A but we are concerned for unvisited nodes only.    4.   Visit D and mark it as visited and put onto the stack. Here, we have B and C nodes, which are adjacent to D and both are unvisited. However, we shall again choose in an alphabetical order.    5.   We choose B, mark it as visited and put onto the stack. Here Bdoes not have any unvisited adjacent node. So, we pop Bfrom the stack.    6.   We check the stack top for return to the previous node and check if it has any unvisited nodes. Here, we find D to be on the top of the stack.    7.   Only unvisited adjacent node is from D is C now. So we visit C, mark it as visited and put it onto the stack.", 
            "title": "Algorithms"
        }, 
        {
            "location": "/graph_bfs/", 
            "text": "Breadth First Traversal\n\n\nBreadth First Search (BFS) algorithm traverses a graph in a breadthward motion and uses a queue to remember to get the next vertex to start a search, when a dead end occurs in any iteration.\n\n\n\n\nAs in the example given above, BFS algorithm traverses from A to B to E to F first then to C and G lastly to D. It employs the following rules.\n\n\n\n\nRule 1\n \u2212 Visit the adjacent unvisited vertex. Mark it as visited. Display it. Insert it * in a queue.\n\n\nRule 2\n \u2212 If no adjacent vertex is found, remove the first vertex from the queue.\n\n\nRule 3\n \u2212 Repeat Rule 1 and Rule 2 until the queue is empty.\n\n\n\n\nAlgorithms\n\n\n\n\n\n\n\n\nStep\n\n\nTraversal\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n1.\n\n\n\n\nInitialize the stack.\n\n\n\n\n\n\n2.\n\n\n\n\nMark S as visited and put it onto the stack. Explore any unvisited adjacent node from S. We have three nodes and we can pick any of them. For this example, we shall take the node in an alphabetical order.\n\n\n\n\n\n\n3.\n\n\n\n\nMark A as visited and put it onto the stack. Explore any unvisited adjacent node from A. Both Sand D are adjacent to A but we are concerned for unvisited nodes only.\n\n\n\n\n\n\n4.\n\n\n\n\nVisit D and mark it as visited and put onto the stack. Here, we have B and C nodes, which are adjacent to D and both are unvisited. However, we shall again choose in an alphabetical order.\n\n\n\n\n\n\n5.\n\n\n\n\nWe choose B, mark it as visited and put onto the stack. Here Bdoes not have any unvisited adjacent node. So, we pop Bfrom the stack.\n\n\n\n\n\n\n6.\n\n\n\n\nWe check the stack top for return to the previous node and check if it has any unvisited nodes. Here, we find D to be on the top of the stack.\n\n\n\n\n\n\n7.\n\n\n\n\nOnly unvisited adjacent node is from D is C now. So we visit C, mark it as visited and put it onto the stack.\n\n\n\n\n\n\n\n\nAt this stage, we are left with no unmarked (unvisited) nodes. But as per the algorithm we keep on dequeuing in order to get all unvisited nodes. When the queue gets emptied, the program is over.", 
            "title": "BFS: Breadth First Traversal"
        }, 
        {
            "location": "/graph_bfs/#breadth-first-traversal", 
            "text": "Breadth First Search (BFS) algorithm traverses a graph in a breadthward motion and uses a queue to remember to get the next vertex to start a search, when a dead end occurs in any iteration.   As in the example given above, BFS algorithm traverses from A to B to E to F first then to C and G lastly to D. It employs the following rules.   Rule 1  \u2212 Visit the adjacent unvisited vertex. Mark it as visited. Display it. Insert it * in a queue.  Rule 2  \u2212 If no adjacent vertex is found, remove the first vertex from the queue.  Rule 3  \u2212 Repeat Rule 1 and Rule 2 until the queue is empty.", 
            "title": "Breadth First Traversal"
        }, 
        {
            "location": "/graph_bfs/#algorithms", 
            "text": "Step  Traversal  Description      1.   Initialize the stack.    2.   Mark S as visited and put it onto the stack. Explore any unvisited adjacent node from S. We have three nodes and we can pick any of them. For this example, we shall take the node in an alphabetical order.    3.   Mark A as visited and put it onto the stack. Explore any unvisited adjacent node from A. Both Sand D are adjacent to A but we are concerned for unvisited nodes only.    4.   Visit D and mark it as visited and put onto the stack. Here, we have B and C nodes, which are adjacent to D and both are unvisited. However, we shall again choose in an alphabetical order.    5.   We choose B, mark it as visited and put onto the stack. Here Bdoes not have any unvisited adjacent node. So, we pop Bfrom the stack.    6.   We check the stack top for return to the previous node and check if it has any unvisited nodes. Here, we find D to be on the top of the stack.    7.   Only unvisited adjacent node is from D is C now. So we visit C, mark it as visited and put it onto the stack.     At this stage, we are left with no unmarked (unvisited) nodes. But as per the algorithm we keep on dequeuing in order to get all unvisited nodes. When the queue gets emptied, the program is over.", 
            "title": "Algorithms"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Suffix Trees"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Burrows-Wheeler Transform and Suffix Arrays"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/d_trie/", 
            "text": "Introduction\n\n\nThere are many algorithms and data structures to index and search strings inside a text, some of them are included in the standard libraries, but not all of them; the trie data structure is a good example of one that isn\u2019t.\n\n\nLet word be a single string and let dictionary be a large set of words. If we have a dictionary, and we need to know if a single word is inside of the dictionary the tries are a data structure that can help us. But you may be asking yourself, \u201cWhy use tries if set \n and hash tables can do the same?\u201d\n\n\nThere are two main reasons:\n\n\n\n\n\n\nThe tries can insert and find strings in \n O(L) \n time (where L represent the length of a single word). This is much faster than set , but is it a bit faster than a hash table.\nThe set \n and the hash tables can only find in a dictionary words that match exactly with the single word that we are finding; the trie allow us to find words that have a single character different, a prefix in common, a character missing, etc.\n\n\n\n\n\n\nThe tries can be useful in TopCoder problems, but also have a great amount of applications in software engineering. For example, consider a web browser. Do you know how the web browser can auto complete your text or show you many possibilities of the text that you could be writing? Yes, with the trie you can do it very fast. Do you know how an orthographic corrector can check that every word that you type is in a dictionary? Again a trie. You can also use a trie for suggested corrections of the words that are present in the text but not in the dictionary.\n\n\n\n\n\n\nWhat is a Tree?\n\n\nYou may read about how wonderful the tries are, but maybe you don\u2019t know yet what the tries are and why the tries have this name. The word trie is an infix of the word \u201cretrieval\u201d because the trie can find a single word in a dictionary with only a prefix of the word. The main idea of the trie data structure consists of the following parts:\n\n\n\n\nThe trie is a tree where each vertex represents a single word or a prefix.\n\n\nThe root represents an empty string (\u201c\u201d), the vertexes that are direct sons of the root represent prefixes of length 1, the vertexes that are 2 edges of distance from the root represent prefixes of length 2, the vertexes that are 3 edges of distance from the root represent prefixes of length 3 and so on. In other words, a vertex that are k edges of distance of the root have an associated prefix of length k.\n\n\nLet v and w be two vertexes of the trie, and assume that v is a direct father of w, then v must have an associated prefix of w.\n\n\n\n\nThe next figure shows a trie with the words \u201ctree\u201d, \u201ctrie\u201d, \u201calgo\u201d, \u201cassoc\u201d, \u201call\u201d, and \u201calso.\u201d\n\n\n\n\n\n\n\n\n\nNote that every vertex of the tree does not store entire prefixes or entire words. The idea is that the program should remember the word that represents each vertex while lower in the tree.\n\n\nCoding a Trie\n\n\nThe tries can be implemented in many ways, some of them can be used to find a set of words in the dictionary where every word can be a little different than the target word, and other implementations of the tries can provide us with only words that match exactly with the target word. The implementation of the trie that will be exposed here will consist only of finding words that match exactly and counting the words that have some prefix. This implementation will be pseudo code because different coders can use different programming languages.\n\n\nWe will code these 4 functions:\n\n\n\n\naddWord\n. This function will add a single string word to the dictionary.\n\n\ncountPreffixes\n. This function will count the number of words in the dictionary that have a string prefix as prefix.\n\n\ncountWords\n. This function will count the number of words in the dictionary that match exactly with a given string word.\n\n\nOur trie will only support letters of the English alphabet.\n\n\n\n\nWe need to also code a structure with some fields that indicate the values stored in each vertex. As we want to know the number of words that match with a given string, every vertex should have a field to indicate that this vertex represents a complete word or only a prefix (for simplicity, a complete word is considered also a prefix) and how many words in the dictionary are represented by that prefix (there can be repeated words in the dictionary). This task can be done with only one integer field words.\n\n\nBecause we want to know the number of words that have like prefix a given string, we need another integer field prefixes that indicates how many words have the prefix of the vertex. Also, each vertex must have references to all his possible sons (26 references). Knowing all these details, our structure should have the following members:\n\n\nstructure Trie\n    integer words;\n    integer prefixes;\n    reference edges[26];\n\n\n\n\nAnd we also need the following functions:\n\n\ninitialize(vertex)\naddWord(vertex, word);\ninteger countPrefixes(vertex, prefix);\ninteger countWords(vertex, word);\n\n\n\n\nFirst of all, we have to initialize the vertexes with the following function:\n\n\ninitialize(vertex)\n    vertex.words=0\n    vertex.prefixes=0\n    for i=0 to 26\n        edges[i]=NoEdge\n\n\n\n\nThe addWord function consists of two parameters, the vertex of the insertion and the word that will be added. The idea is that when a string word is added to a vertex vertex, we will add word to the corresponding branch of vertex cutting the leftmost character of word. If the needed branch does not exist, we will have to create it. All the TopCoder languages can simulate the process of cutting a character in constant time instead of creating a copy of the original string or moving the other characters.\n\n\naddWord(vertex, word)\n    if isEmpty(word)\n        vertex.words=vertex.words+1\n    else\n        vertex.prefixes=vertex.prefixes+1\n        k=firstCharacter(word)\n        if(notExists(edges[k]))\n            edges[k]=createEdge()\n            initialize(edges[k])\n        cutLeftmostCharacter(word)\n        addWord(edges[k], word)\n\n\n\n\nThe functions countWords and countPrefixes are very similar. If we are finding an empty string we only have to return the number of words/prefixes associated with the vertex. If we are finding a non-empty string, we should to find in the corresponding branch of the tree, but if the branch does not exist, we have to return 0.\n\n\ncountWords(vertex, word)\n    k=firstCharacter(word)\n    if isEmpty(word)\n        return vertex.words\n    else if notExists(edges[k])\n        return 0\n    else\n        cutLeftmostCharacter(word)\n        return countWords(edges[k], word);\n\ncountPrefixes(vertex, prefix)\n    k=firstCharacter(prefix)\n    if isEmpty(word)\n        return vertex.prefixes\n    else if notExists(edges[k])\n        return 0\n    else\n        cutLeftmostCharacter(prefix)\n        return countWords(edges[k], prefix)\n\n\n\n\nComplexity Analysis\n\n\nIn the introduction you may read that the complexity of finding and inserting a trie is linear, but we have not done the analysis yet. In the insertion and finding notice that lowering a single level in the tree is done in constant time, and every time that the program lowers a single level in the tree, a single character is cut from the string; we can conclude that every function lowers L levels on the tree and every time that the function lowers a level on the tree, it is done in constant time, then the insertion and finding of a word in a trie can be done in O(L) time. The memory used in the tries depends on the methods to store the edges and how many words have prefixes in common.\n\n\nOther Kinds of Tries\n\n\nWe used the tries to store words with lowercase letters, but the tries can be used to store many other things. We can use bits or bytes instead of lowercase letters and every data type can be stored in the tree, not only strings. Let flow your imagination using tries! For example, suppose that you want to find a word in a dictionary but a single letter was deleted from the word. You can modify the countWords function:\n\n\ncountWords(vertex, word, missingLetters)\n    k=firstCharacter(word)\n    if isEmpty(word)\n        return vertex.word\n    else if notExists(edges[k]) and missingLetters=0\n        return 0\n    else if notExists(edges[k])\n        cutLeftmostCharacter(word)\n        return countWords(vertex, word, missingLetters-1)\n        Here we cut a character but we don't go lower in the tree\n    else\n        We are adding the two possibilities: the first\n        character has been deleted plus the first character is present\n        r=countWords(vertex, word, missingLetters-1)\n        cutLeftmostCharacter(word)\n        r=r+countWords(edges[k], word, missingLetters)\n        return r\n\n\n\n\nThe complexity of this function may be larger than the original, but it is faster than checking all the subsets of characters of a word.\n\n\nChallenges\n\n\n\n\n\"Tries: Contacts\". \nhackerrank\n. 2016\n\n\n\n\nReferences\n\n\n\n\n\"Using Tries \u2013 Topcoder\".\u00a0\nTopcoder.com\n. N.p., 2016. Web. 11 Oct. 2016.", 
            "title": "Tries"
        }, 
        {
            "location": "/d_trie/#introduction", 
            "text": "There are many algorithms and data structures to index and search strings inside a text, some of them are included in the standard libraries, but not all of them; the trie data structure is a good example of one that isn\u2019t.  Let word be a single string and let dictionary be a large set of words. If we have a dictionary, and we need to know if a single word is inside of the dictionary the tries are a data structure that can help us. But you may be asking yourself, \u201cWhy use tries if set   and hash tables can do the same?\u201d  There are two main reasons:    The tries can insert and find strings in   O(L)   time (where L represent the length of a single word). This is much faster than set , but is it a bit faster than a hash table.\nThe set   and the hash tables can only find in a dictionary words that match exactly with the single word that we are finding; the trie allow us to find words that have a single character different, a prefix in common, a character missing, etc.    The tries can be useful in TopCoder problems, but also have a great amount of applications in software engineering. For example, consider a web browser. Do you know how the web browser can auto complete your text or show you many possibilities of the text that you could be writing? Yes, with the trie you can do it very fast. Do you know how an orthographic corrector can check that every word that you type is in a dictionary? Again a trie. You can also use a trie for suggested corrections of the words that are present in the text but not in the dictionary.", 
            "title": "Introduction"
        }, 
        {
            "location": "/d_trie/#what-is-a-tree", 
            "text": "You may read about how wonderful the tries are, but maybe you don\u2019t know yet what the tries are and why the tries have this name. The word trie is an infix of the word \u201cretrieval\u201d because the trie can find a single word in a dictionary with only a prefix of the word. The main idea of the trie data structure consists of the following parts:   The trie is a tree where each vertex represents a single word or a prefix.  The root represents an empty string (\u201c\u201d), the vertexes that are direct sons of the root represent prefixes of length 1, the vertexes that are 2 edges of distance from the root represent prefixes of length 2, the vertexes that are 3 edges of distance from the root represent prefixes of length 3 and so on. In other words, a vertex that are k edges of distance of the root have an associated prefix of length k.  Let v and w be two vertexes of the trie, and assume that v is a direct father of w, then v must have an associated prefix of w.   The next figure shows a trie with the words \u201ctree\u201d, \u201ctrie\u201d, \u201calgo\u201d, \u201cassoc\u201d, \u201call\u201d, and \u201calso.\u201d     Note that every vertex of the tree does not store entire prefixes or entire words. The idea is that the program should remember the word that represents each vertex while lower in the tree.", 
            "title": "What is a Tree?"
        }, 
        {
            "location": "/d_trie/#coding-a-trie", 
            "text": "The tries can be implemented in many ways, some of them can be used to find a set of words in the dictionary where every word can be a little different than the target word, and other implementations of the tries can provide us with only words that match exactly with the target word. The implementation of the trie that will be exposed here will consist only of finding words that match exactly and counting the words that have some prefix. This implementation will be pseudo code because different coders can use different programming languages.  We will code these 4 functions:   addWord . This function will add a single string word to the dictionary.  countPreffixes . This function will count the number of words in the dictionary that have a string prefix as prefix.  countWords . This function will count the number of words in the dictionary that match exactly with a given string word.  Our trie will only support letters of the English alphabet.   We need to also code a structure with some fields that indicate the values stored in each vertex. As we want to know the number of words that match with a given string, every vertex should have a field to indicate that this vertex represents a complete word or only a prefix (for simplicity, a complete word is considered also a prefix) and how many words in the dictionary are represented by that prefix (there can be repeated words in the dictionary). This task can be done with only one integer field words.  Because we want to know the number of words that have like prefix a given string, we need another integer field prefixes that indicates how many words have the prefix of the vertex. Also, each vertex must have references to all his possible sons (26 references). Knowing all these details, our structure should have the following members:  structure Trie\n    integer words;\n    integer prefixes;\n    reference edges[26];  And we also need the following functions:  initialize(vertex)\naddWord(vertex, word);\ninteger countPrefixes(vertex, prefix);\ninteger countWords(vertex, word);  First of all, we have to initialize the vertexes with the following function:  initialize(vertex)\n    vertex.words=0\n    vertex.prefixes=0\n    for i=0 to 26\n        edges[i]=NoEdge  The addWord function consists of two parameters, the vertex of the insertion and the word that will be added. The idea is that when a string word is added to a vertex vertex, we will add word to the corresponding branch of vertex cutting the leftmost character of word. If the needed branch does not exist, we will have to create it. All the TopCoder languages can simulate the process of cutting a character in constant time instead of creating a copy of the original string or moving the other characters.  addWord(vertex, word)\n    if isEmpty(word)\n        vertex.words=vertex.words+1\n    else\n        vertex.prefixes=vertex.prefixes+1\n        k=firstCharacter(word)\n        if(notExists(edges[k]))\n            edges[k]=createEdge()\n            initialize(edges[k])\n        cutLeftmostCharacter(word)\n        addWord(edges[k], word)  The functions countWords and countPrefixes are very similar. If we are finding an empty string we only have to return the number of words/prefixes associated with the vertex. If we are finding a non-empty string, we should to find in the corresponding branch of the tree, but if the branch does not exist, we have to return 0.  countWords(vertex, word)\n    k=firstCharacter(word)\n    if isEmpty(word)\n        return vertex.words\n    else if notExists(edges[k])\n        return 0\n    else\n        cutLeftmostCharacter(word)\n        return countWords(edges[k], word);\n\ncountPrefixes(vertex, prefix)\n    k=firstCharacter(prefix)\n    if isEmpty(word)\n        return vertex.prefixes\n    else if notExists(edges[k])\n        return 0\n    else\n        cutLeftmostCharacter(prefix)\n        return countWords(edges[k], prefix)", 
            "title": "Coding a Trie"
        }, 
        {
            "location": "/d_trie/#complexity-analysis", 
            "text": "In the introduction you may read that the complexity of finding and inserting a trie is linear, but we have not done the analysis yet. In the insertion and finding notice that lowering a single level in the tree is done in constant time, and every time that the program lowers a single level in the tree, a single character is cut from the string; we can conclude that every function lowers L levels on the tree and every time that the function lowers a level on the tree, it is done in constant time, then the insertion and finding of a word in a trie can be done in O(L) time. The memory used in the tries depends on the methods to store the edges and how many words have prefixes in common.", 
            "title": "Complexity Analysis"
        }, 
        {
            "location": "/d_trie/#other-kinds-of-tries", 
            "text": "We used the tries to store words with lowercase letters, but the tries can be used to store many other things. We can use bits or bytes instead of lowercase letters and every data type can be stored in the tree, not only strings. Let flow your imagination using tries! For example, suppose that you want to find a word in a dictionary but a single letter was deleted from the word. You can modify the countWords function:  countWords(vertex, word, missingLetters)\n    k=firstCharacter(word)\n    if isEmpty(word)\n        return vertex.word\n    else if notExists(edges[k]) and missingLetters=0\n        return 0\n    else if notExists(edges[k])\n        cutLeftmostCharacter(word)\n        return countWords(vertex, word, missingLetters-1)\n        Here we cut a character but we don't go lower in the tree\n    else\n        We are adding the two possibilities: the first\n        character has been deleted plus the first character is present\n        r=countWords(vertex, word, missingLetters-1)\n        cutLeftmostCharacter(word)\n        r=r+countWords(edges[k], word, missingLetters)\n        return r  The complexity of this function may be larger than the original, but it is faster than checking all the subsets of characters of a word.", 
            "title": "Other Kinds of Tries"
        }, 
        {
            "location": "/d_trie/#challenges", 
            "text": "\"Tries: Contacts\".  hackerrank . 2016", 
            "title": "Challenges"
        }, 
        {
            "location": "/d_trie/#references", 
            "text": "\"Using Tries \u2013 Topcoder\".\u00a0 Topcoder.com . N.p., 2016. Web. 11 Oct. 2016.", 
            "title": "References"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Knuth\u2013Morris\u2013Pratt Algorithm"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Constructing Suffix Arrays and Suffix Trees"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Complete coloring"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Clique cover problem"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Knapsack problem"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Bin packing problem"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Closest string"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Longest common subsequence problem"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Flows in Networks"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }, 
        {
            "location": "/", 
            "text": "Data Structures \n Algorithms Tutorial \nby MG\n\n\n\n\nAlgorithms + Data Structures = Programs\n\n\nIn computer science, a \ndata structure\n is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.\n\n\nIn mathematics and computer science, an \nalgorithm\n is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.\n\n\n\n\nTable of Contents\n\n\nThis site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms. \n\n\nGet Started\n\n\n\n\nIntroduction\n\n\nGreedy Algorithms\n\n\nDivide-and-Conquer\n\n\nDynamic Programming\n\n\n7 Steps to Solve Algorithm Problems\n\n\n\n\nData Structures\n\n\n\n\nArrays\n\n\nLinked List\n\n\nStacks \n Queues\n\n\nTrees\n\n\nHash Tables\n\n\nBinary Search Trees\n\n\nHeaps\n\n\n\n\nAlgorithms on Graphs\n\n\n\n\nGraph Data Structure\n\n\nDFS: Depth First Traversal\n\n\nBFS: Breadth First Traversal\n\n\n\n\nAlgorithms on Strings\n\n\n\n\nSuffix Trees\n\n\nBurrows-Wheeler Transform and Suffix Arrays\n\n\nKnuth\u2013Morris\u2013Pratt Algorithm\n\n\nConstructing Suffix Arrays and Suffix Trees\n\n\n\n\nNP-complete Problems\n\n\n\n\nComplete coloring\n\n\nClique cover problem\n\n\nKnapsack problem\n\n\nBin packing problem\n\n\nClosest string\n\n\nLongest common subsequence problem\n\n\n\n\nAdvanced Algorithms and Complexity\n\n\n\n\nFlows in Networks\n\n\nLinear Programming\n\n\n\n\nMiscellaneous\n\n\n\n\nBest algorithms and data structures books\n\n\nBest algorithms and data structures courses\n\n\nData Structures and Algorithms Challenges\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\nhttps://www.topcoder.com/\n\n\nhttps://www.hackerrank.com/\n\n\nhttp://codeforces.com/\n\n\nhttps://www.codechef.com/\n\n\nhttp://www.spoj.com/\n\n\nhttps://projecteuler.net/", 
            "title": "Linear Programming"
        }, 
        {
            "location": "/#data-structures-algorithms-tutorial-by-mg", 
            "text": "Algorithms + Data Structures = Programs  In computer science, a  data structure  is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computional complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.  In mathematics and computer science, an  algorithm  is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.", 
            "title": "Data Structures &amp; Algorithms Tutorial by MG"
        }, 
        {
            "location": "/#table-of-contents", 
            "text": "This site is intended to host a variety of resources and pointers to information about Data Structures and Algorithms.", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/#get-started", 
            "text": "Introduction  Greedy Algorithms  Divide-and-Conquer  Dynamic Programming  7 Steps to Solve Algorithm Problems", 
            "title": "Get Started"
        }, 
        {
            "location": "/#data-structures", 
            "text": "Arrays  Linked List  Stacks   Queues  Trees  Hash Tables  Binary Search Trees  Heaps", 
            "title": "Data Structures"
        }, 
        {
            "location": "/#algorithms-on-graphs", 
            "text": "Graph Data Structure  DFS: Depth First Traversal  BFS: Breadth First Traversal", 
            "title": "Algorithms on Graphs"
        }, 
        {
            "location": "/#algorithms-on-strings", 
            "text": "Suffix Trees  Burrows-Wheeler Transform and Suffix Arrays  Knuth\u2013Morris\u2013Pratt Algorithm  Constructing Suffix Arrays and Suffix Trees", 
            "title": "Algorithms on Strings"
        }, 
        {
            "location": "/#np-complete-problems", 
            "text": "Complete coloring  Clique cover problem  Knapsack problem  Bin packing problem  Closest string  Longest common subsequence problem", 
            "title": "NP-complete Problems"
        }, 
        {
            "location": "/#advanced-algorithms-and-complexity", 
            "text": "Flows in Networks  Linear Programming", 
            "title": "Advanced Algorithms and Complexity"
        }, 
        {
            "location": "/#miscellaneous", 
            "text": "Best algorithms and data structures books  Best algorithms and data structures courses  Data Structures and Algorithms Challenges", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#challenges", 
            "text": "https://www.topcoder.com/  https://www.hackerrank.com/  http://codeforces.com/  https://www.codechef.com/  http://www.spoj.com/  https://projecteuler.net/", 
            "title": "Challenges"
        }
    ]
}